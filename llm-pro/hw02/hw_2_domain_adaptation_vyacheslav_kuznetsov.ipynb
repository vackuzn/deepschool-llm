{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78456479",
      "metadata": {},
      "source": [
        "# Домашнее задание 2\n",
        "\n",
        "В этом задании вам предстоит реализовать контрастивное обучние эмбеддера, посмотреть на его влияние на задаче классификации и отбора кандидатов.\n",
        "\n",
        "Языковое моделирование рассматривать не будем в силу дороговизны подхода."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a366fa7d",
      "metadata": {},
      "source": [
        "## Часть 1. Triplet loss на стероидах\n",
        "\n",
        "Вам поставили задачу: на фиксированном множестве точек произвести классификацию, при этом множество таково, что качество на исходных данных неприемлемо. Что делать? Последуем совету из лекции и реализуем контрастивное обучение.\n",
        "\n",
        "В этом и последующем задании вам предстоит реализовать предобучение некоторого простого эмбеддера на домен.\n",
        "\n",
        "Эмбеддинги заморожены -- будем дообучать только полносвязную голову."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ee97fc5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca3d3cb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "\n",
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    n_samples: int = 5000\n",
        "    n_features: int = 32\n",
        "    n_classes: int = 8\n",
        "    n_clusters_per_class: int = 2\n",
        "    n_informative: int = 5\n",
        "    random_state: int = SEED\n",
        "\n",
        "@dataclass\n",
        "class SplitConfig:\n",
        "    random_state: int = SEED\n",
        "    test_size: float = 0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7930aa88",
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(**DatasetConfig().__dict__)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, **SplitConfig().__dict__)\n",
        "X_train, y_train = torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eae9e3c6",
      "metadata": {},
      "source": [
        "## 1.Визуализация данных - 1 баллов\n",
        "\n",
        "Напишите функцию `plot_tsne(data, labels, **kwargs)`, принимающую на вход матрицу эмбеддингов и метки классификации и строящую t-SNE-разложение на плоскости. Изобразите его, раскрасив классы по цветам. Зафиксируйте `random_state` при построении."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1faf7c7d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Красиво накидываем точки на плоскость\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8107f5b",
      "metadata": {},
      "source": [
        "## 2.Базовый классификатор - 1 балл\n",
        "\n",
        "Выберите алгоритм классификации, который вам больше нравится (но советую взять kNN). Возьмите accuracy в качестве метрики качества классификации. Оцените базовое качество на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68da79ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Плотно классифицируем тест\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee99b99a",
      "metadata": {},
      "source": [
        "## 3.TripletLoss - 5 баллов\n",
        "\n",
        "Заметим, что в случае L2-нормилизованных векторов:\n",
        "\n",
        "$$\\max\\left(0,\\|f(x)-f(x^+)\\|^2_2-\\|f(x)-f(x^-)\\|^2_2+\\varepsilon\\right)=\\max\\left(0,f(x)f^T(x^-)-f(x)f^T(x^+)+\\varepsilon\\right)$$\n",
        "\n",
        "Выше записан triplet loss. Его мы будем реализовывать, но с некоторой упрощающей модификацией.\n",
        "\n",
        "Пусть $D=\\{x_i, y_i\\}_i$ -- выборка классификации. Пусть $S=XX^T$. Кто будет формировать позитивы? Такие $j\\neq i:\\;y_i=y_j$ -- диагональ $S$ вырезается. При этом по матрице $S$ можно сформировать два непересекающихся множества: позитивов $P$ и негативов $N$ (как оставшихся пар, где $y_i\\neq y_j$). Пусть $L$ -- минимальная мощность этих двух множеств. Возьмем $\\hat{P}=\\{p_i\\}_i$, $\\hat{N}=\\{n_i\\}_i$ как сэмплы размера $L$ из $P$ и $N$ соответственно. Тогда итоговая функция ошибки выглядит так:\n",
        "\n",
        "$$\\mathcal{L}=\\frac{1}{L}\\sum\\limits_{i=1}^L\\max\\left(0, n_i-p_i+\\varepsilon\\right)$$\n",
        "\n",
        "В чем модификация? В том, что в паре позитивов и негативов не обязательно должен быть один и тот же якорный элемент. И это работает.\n",
        "\n",
        "Реализуйте callable-класс `TripletLoss` по описанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4419cd59",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "class TripletLoss():\n",
        "    \n",
        "    def __init__(self, margin, random_state=None):\n",
        "        self.margin = margin\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def __call__(self, x, labels):\n",
        "        raise NotImplementedError()\n",
        "# ---- Конец кода ----\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8016e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = TripletLoss(0.2, random_state=101)\n",
        "\n",
        "\n",
        "objects = torch.tensor(\n",
        "    [[-1.7651, -1.5979,  0.1042,  0.3825, -0.9419, -0.2580, -0.6087, -0.1711,\n",
        "        1.3922,  0.8548, -0.9251,  0.6989,  0.4238, -0.1330,  0.2985],\n",
        "    [ 1.6144,  0.0627,  0.3424, -0.8591,  0.1869, -0.8598, -0.7200,  0.9449,\n",
        "        -0.1684,  1.0282, -1.2377, -1.2640,  0.7469,  1.9605, -0.1214],\n",
        "    [ 1.1143, -0.6948,  0.3739, -1.1461,  0.6456, -0.3360, -0.8111, -0.8861,\n",
        "        0.7176, -0.6235, -0.9364,  0.6174,  2.7212, -2.0703, -2.2571],\n",
        "    [ 0.7525,  2.1028,  2.7782,  0.5040, -1.5791,  1.5342,  0.0816,  0.3245,\n",
        "        -0.0857, -0.5992, -1.4339,  0.0897, -1.5096,  0.1428, -0.1488],\n",
        "    [-0.7518,  0.2623, -0.4958, -1.6063,  0.2537, -0.1137,  0.3985,  1.0155,\n",
        "        0.1874, -0.4300, -1.2309,  1.5760, -1.3176,  1.5355,  1.8471],\n",
        "    [ 1.9290, -0.3236,  0.4303,  0.7111,  1.4234,  1.7901,  0.2216, -1.5471,\n",
        "        0.9389, -0.3012, -1.6487,  1.5765, -1.1450,  0.3260,  0.4909],\n",
        "    [ 0.7837, -0.8004, -0.0929, -1.2220,  2.2333,  0.3288, -0.5222, -0.7202,\n",
        "        0.6147,  1.8012, -0.2388, -0.2539,  0.0191, -0.0104,  0.5717],\n",
        "    [-0.2709, -1.7985, -0.3959, -1.1190,  0.8644,  0.3008, -1.0336, -0.1251,\n",
        "        -0.3357,  0.7938,  3.2090, -0.4332, -0.0496, -0.2672,  0.9690],\n",
        "    [-0.1109,  0.4130,  0.7406, -1.2446, -0.4252,  2.5128, -0.2765,  0.6845,\n",
        "        1.1965,  1.4173, -1.4604,  0.2515,  0.6387, -1.8519,  1.1899],\n",
        "    [-0.1781, -0.7473, -0.1015,  0.2280, -1.5815,  0.1535, -1.3912, -2.2026,\n",
        "        1.0496,  0.3547,  0.8897, -0.6482,  0.0133,  1.0124, -0.4452]])\n",
        "\n",
        "labels = torch.LongTensor([1, 1, 2, 2, 3, 3, 4, 4, 5, 5])\n",
        "assert abs(criterion(objects, labels).item() - 0.29527) < 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40ca958",
      "metadata": {},
      "source": [
        "## 4.Модель и функция обучения - 8 балла\n",
        "\n",
        "Реализуйте класс `MLP`, полносвязную нейронную сеть. Выбирайте на свой вкус.\n",
        "\n",
        "Реализуйте функцию `domain_adaptation`, стандартный цикл batch-обучения модели. Батч можно сэмплировать произвольно через `choice`.\n",
        "\n",
        "Требуется выбить на тесте 0.60 точности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef752a01",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Задаем полносвязную простенькую сетку\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66166b95",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Учим эмбеддер\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e1f5d1a",
      "metadata": {},
      "source": [
        "## 5.Итоговое качество - 1 балл\n",
        "\n",
        "Отобразите новое распределение t-SNE-координат и посчитайте тестовую метрику. Сделайте краткий вывод."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d17b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Визуализируем успех\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae4c9a4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Считаем точность на тесте\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4ebac6",
      "metadata": {},
      "source": [
        "## Часть 2. Triplet loss на чем-то посерьезнее\n",
        "\n",
        "Рассмотрим теперь более живую задачу классификации. Будем работать с новостными группами.\n",
        "\n",
        "Постановка та же, только возьмем теперь предобученный эмбеддер с HF. Эмбеддинги заморожены -- будем дообучать только полносвязную голову."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d440bf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13c6f0a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "categories = [\n",
        "    \"sci.space\",\n",
        "    \"sci.med\",\n",
        "    \"sci.electronics\",\n",
        "    \"comp.os.ms-windows.misc\",\n",
        "    \"comp.sys.ibm.pc.hardware\",\n",
        "    \"comp.sys.mac.hardware\"\n",
        "]\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset=\"train\", categories=categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset=\"test\", categories=categories)\n",
        "\n",
        "X_train = newsgroups_train.data\n",
        "X_test = newsgroups_test.data\n",
        "\n",
        "y_train = newsgroups_train.target\n",
        "y_test = newsgroups_test.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "980b152d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_logreg(X_train_mapped, y_train, X_test_mapped, y_test, target_names=newsgroups_test.target_names):\n",
        "    clf = LogisticRegression(max_iter=10000)\n",
        "    clf.fit(X_train_mapped, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_test_mapped)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "    print(f\"Accuracy: {score:.3f}\")\n",
        "    print(f\"Classification Report: {report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529cb30a",
      "metadata": {},
      "source": [
        "## 1.Выбираем англоязычный эмбеддер и формируем эмбеддинги - 1 балл\n",
        "\n",
        "Выберите небольшой англоязычный sentence-трансформер, обученный на семантику, и прогоните через нее тексты обучения и тестирования.\n",
        "\n",
        "Замерьте базовое качество классификатора на этих эмбеддингах.\n",
        "\n",
        "Опционально: крайне рекомендую прогнать `plot_tsne` из прошлой части на тесте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33816bc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Определяем модель, получаем эмбеддинги, визуализируем тест через t-SNE\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcd31de0",
      "metadata": {},
      "source": [
        "## 2.Обучаем эмбеддинги под задачу - 1 балл\n",
        "\n",
        "Теперь точно придется обратиться к Части 1. Необходимо взять `domain adaptation` и обучить эмбеддиги на домен."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b25d7db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Доменно адаптируемся\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1215b3a5",
      "metadata": {},
      "source": [
        "## 3.Замеряем качество - 1 балл\n",
        "\n",
        "Обучитите базовый классификатор на новом пространстве эмбеддингов, сравните результаты, напишите вывод.\n",
        "\n",
        "Опционально: вновь крайне рекомендую прогнать `plot_tsne` из прошлой части на тесте, только уже в новом пространстве."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35eddd8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Радуемся росту качества\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29a629bc",
      "metadata": {},
      "source": [
        "# Часть 3. Контрастивное обучение для поискового отбора кандидатов.\n",
        "\n",
        "Эта часть будет более кейс-ориентированной, мы разберем сценарий, в котором контрастивное обучение является стандартной практикой улучшения качества модели на конечной задаче.\n",
        "\n",
        "Бизнес-кейс:\n",
        "> Требуется улучшить этап отбора кандидатов в поисковой веб-системе. На текущий момент в качестве кандгена (кандидатогенерации) используется BM25 и обратный индекс. BM25 уже тюнили, дальше качество нарастить не выходит. В качестве бизнес-метрики можем взять производные поведенческого отклика, например, CTR@K или timespent на выдаче и документах.\n",
        "\n",
        "Очевидным направлением развития является построение нейросетевого кандгена. Обычно в описанных случаях действуют следующим образом:\n",
        "0. Выбирают ML-метрику, которую хотелось бы оптимизировать. Для кандгена катастрофически важно выдать как можно больше релеватных документов в пределах фиксированной длины выдачи, поэтому подходящая метрика -- Recall@K. Мы будем использовать ее модификацию, но об этом позже.\n",
        "1. Сэмплируют запросы из потока / формируют специфичные корзины запросов в зависимости от дополнительных бизнес-требований. Давайте считать, что они отсутствуют. Тут обязателен контроль их качества, можно исходить из символьных эвристик или применять LLM для классификации, как вы это делали в предыдущей домашке.\n",
        "2. Обкачивают поисковый движок, формируя глубокие выдачи. Эпитет \"глубокие\" относится к глубине погружения пользователя в выдачу, то есть предельные позиции взаимодействия с документами. Так вот для обучения требуется брать документов в избытке, в том числе те, с которыми пользователь никогда бы не повзаимодействовал. В целом, длина выдачи 1000 -- отличный выбор. Предварительно есть смысл сгладить все условия отбора по BM25.\n",
        "3. Разметка пар запрос-документ на задачу релевантности. LLM -- вновь отличный выбор. Разметка порядковая, но может быть как бинарной, так и n-арной. Важно сформировать определение \"релевантного\" документа, то есть определить порог, по которому мы будем считать документ подходящим под запрос.\n",
        "4. Релевантные пары запрос-документ берем в качестве позитивов, выбираем базовый эмбеддер и учим его контрастивно как bi-энкодер на эту выборку, негативы можем формировать в режиме in-batch.\n",
        "5. Если все сделано верно (данных достаточно, гиперпараметры подобраны, код не багованный), естественным следствием будет рост качества, поздравляю.\n",
        "\n",
        "Датасет, на котором мы будем строить кандген -- MS Marco Dev. В качестве эмбеддера вы вольны использовать любые модели, которые не учились на MS Marco, например, `\"microsoft/deberta-v3-small\"`.\n",
        "\n",
        "Мы привыкли в основном, что датасеты собраны на HF, но в этот раз рассмотрим другую библиотеку для работы с датасетами, `ir_datasets` ([API](https://ir-datasets.com/python.html)). \"IR\" от Information Retrieval - библиотека содержит инструменты работы с датасетами поиска. Также в коде будет использоваться `polars` ([API](https://docs.pola.rs/api/python/stable/reference/index.html)), аналог всеми известной `pandas`, только на порядки быстрее.\n",
        "\n",
        "Описание датасета читайте [тут](https://ir-datasets.com/msmarco-passage.html#msmarco-passage/dev/judged)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c556fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from collections import defaultdict\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import ir_datasets\n",
        "import polars as pl\n",
        "\n",
        "import faiss\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7031c549-4e60-4fcf-b8cf-922305ff98ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3555a6b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Columns:\n",
        "    query_id: str = \"query_id\"\n",
        "    doc_id: str = \"doc_id\"\n",
        "    index_id: str = \"index_id\"\n",
        "    text: str = \"text\"\n",
        "    qrels_relevance: str = \"relevance\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DatasetConfig:\n",
        "    sampled_index_size: int = 150_000\n",
        "    relevance_threshold: int = 1\n",
        "    test_size: float = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea7f96e",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = ir_datasets.load(\"msmarco-passage/dev/judged\")\n",
        "\n",
        "columns = Columns()\n",
        "dataset_config = DatasetConfig()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d16386",
      "metadata": {},
      "outputs": [],
      "source": [
        "queries = pl.DataFrame(dataset.queries_iter()).select(\n",
        "    pl.col(columns.query_id).cast(pl.Int32),\n",
        "    pl.col(columns.text)\n",
        ")\n",
        "\n",
        "qrels = pl.DataFrame(dataset.qrels_iter()).drop(\"iteration\").select(\n",
        "    pl.col(columns.query_id).cast(pl.Int32),\n",
        "    pl.col(columns.doc_id).cast(pl.Int32),\n",
        "    pl.col(columns.qrels_relevance).cast(pl.Int32)\n",
        ")\n",
        "\n",
        "documents = pl.DataFrame(dataset.docs_iter()).select(\n",
        "    pl.col(columns.doc_id).cast(pl.Int32),\n",
        "    pl.col(columns.text)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ad865e-535c-4bd8-aa78-6dc2a0b9db75",
      "metadata": {},
      "outputs": [],
      "source": [
        "target_document_ids = qrels[columns.doc_id].unique().to_list()\n",
        "sampled_document_ids = np.random.default_rng().integers(dataset.docs_count(), size=dataset_config.sampled_index_size).tolist()\n",
        "\n",
        "sampled_documents = documents.filter(pl.col(columns.doc_id).is_in(sampled_document_ids + target_document_ids)).with_row_index(columns.index_id)\n",
        "len(target_document_ids), len(sampled_document_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c41d75-fc40-4277-abd7-904ff3d55746",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_qrels, test_qrels = train_test_split(qrels, test_size=dataset_config.test_size)\n",
        "\n",
        "train_queries = queries.filter(pl.col(columns.query_id).is_in(train_qrels[columns.query_id].implode()))\n",
        "test_queries = queries.filter(pl.col(columns.query_id).is_in(test_qrels[columns.query_id].implode()))\n",
        "\n",
        "train_documents = sampled_documents.filter(pl.col(columns.doc_id).is_in(train_qrels[columns.doc_id].implode()))\n",
        "test_documents = sampled_documents.filter(pl.col(columns.doc_id).is_in(test_qrels[columns.doc_id].implode()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71620c7a",
      "metadata": {},
      "source": [
        "## 0.Дополните параметры конфигов в зависимости от вашей реализации модели и обучения\n",
        "\n",
        "Задайте параметры токенизации, обучения, значения параметров функции ошибки и дополнительные параметры модели.\n",
        "Что стоит добавить в конфиг модели:\n",
        "- возможность заморозить хвост и дообучать только голову (делается через регулярки и `model.named_parameters()`)\n",
        "- снижение размерности за счет дополнительной полносвязной сети\n",
        "- параметры для этой дополнительной сети\n",
        "\n",
        "Описание полей конфига функции ошибки читай ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a227b26",
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class TrainTestConfig:\n",
        "    device: str = torch.device([\"cpu\", \"cuda\"][torch.cuda.is_available()])\n",
        "# ---- Ваш код здесь ----\n",
        "# ---- Конец кода ----\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    model_name: str\n",
        "# ---- Ваш код здесь ----\n",
        "# ---- Конец кода ----\n",
        "\n",
        "@dataclass\n",
        "class LossConfig:\n",
        "# ---- Ваш код здесь ----\n",
        "    thrsh: float = ...\n",
        "    temperature: float = ...\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf12b69",
      "metadata": {},
      "outputs": [],
      "source": [
        "columns = Columns()\n",
        "dataset_config = DatasetConfig()\n",
        "train_test_config = TrainTestConfig()\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "model_config = ModelConfig(...)\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "218b396c-d700-47ae-8ad9-e7ee3b430dfb",
      "metadata": {},
      "source": [
        "## 1.Датасет - 4 баллов\n",
        "\n",
        "Напишите класс `DenseRetrievalDataset`, наследованный от `Dataset`, который внутри формирует множество релевантных пар и выдает на каждый индекс произвольную пару оттуда вместе с `query_id` и `doc_id`.\n",
        "\n",
        "Напишите также функцию `train_collate_fn` для DataLoader'а, которая внутри токенизирует батчем текст запроса и документа и отдает кортеж из тензоров, в которые включаются id запросов и документов, токены запросов и документов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c554ae6",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DenseRetrievalDataset(Dataset):\n",
        "    def __init__(self, queries, documents, qrels, columns, config):\n",
        "        self.columns = columns\n",
        "        self.config = config\n",
        "\n",
        "        self.queries = queries\n",
        "        self.documents = documents\n",
        "# ---- Ваш код здесь ----\n",
        "        self.qrels = ...\n",
        "# ---- Конец кода ----\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a40abbf-5007-489e-92d6-d879b6196ef5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_collate_fn(data, tokenizer, config):\n",
        "# ---- Ваш код здесь ----\n",
        "    raise NotImplementedError()\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4fd947c-be17-4693-9d48-e7e6b7802436",
      "metadata": {},
      "source": [
        "## 2.Функция ошибки - 5 баллов\n",
        "\n",
        "Реализуйте класс `ContrastiveLoss`, который реализует расчет следующей функции ошибки:\n",
        "$$\\mathcal{L}=\\mathbb{E}_T\\text{CrossEntropy}\\left(q_iD^T-B_i, M_i\\right)$$\n",
        "$$T=\\{Q, D\\},\\quad Q=\\{q_i\\big|q_i\\in\\mathbb{R}^n,\\|q_i\\|_2=1\\}_{i=1}^N,\\quad D=\\{d_i\\big|d_i\\in\\mathbb{R}^n,\\|d_i\\|_2=1\\}_{i=1}^N$$\n",
        "$$(q_i, d_i) \\,-\\,\\text{позитивная пара}$$\n",
        "$$M_i\\in[0,1]^N,\\quad \\forall{j}\\in\\overline{1,N}:\\;M[j]=\\frac{[q_i = q_j]}{\\sum\\limits_k{[q_i=q_k]}}$$\n",
        "$$B_i\\in[0,1]^N,\\quad \\forall{j}\\in\\overline{1,N}:\\;M[j]=b*[q_i = q_j]$$\n",
        "$$b\\,-\\,\\text{вещественный гиперпараметр}$$\n",
        "\n",
        "Смысл $b$ смотрите в [статье LaBSE](https://arxiv.org/pdf/2007.01852), _Additive Margin Softmax_.\n",
        "\n",
        "Фактически вы напишите InfoNCE с in-batch-негативами.\n",
        "\n",
        "Подсказка: не упаковывайте расчет $M_i$ внутрь функции ошибки, сделайте ее внешней. Она вам пригодится в функции обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d37f74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, thrsh, temperature):\n",
        "        super().__init__()\n",
        "        self.thrsh = thrsh\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, queries, documents, labels):\n",
        "        raise NotImplementedError()\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed92f765",
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = ContrastiveLoss(0.1, 0.05)\n",
        "\n",
        "\n",
        "queries = torch.tensor(\n",
        "    [[ 0.5803,  0.9579, -1.7393,  0.8502,  1.0579,  1.1222, -1.3303,  2.1554,\n",
        "        -0.2404,  1.7580,  0.1433,  0.6232, -0.9371,  0.7069,  0.9060],\n",
        "    [ 1.4968, -0.4212, -0.3566, -0.1982,  0.3722,  0.4442,  1.0164,  0.8380,\n",
        "        -0.5248, -1.1686,  1.3973, -0.6910, -0.5832, -0.2636, -1.0497],\n",
        "    [ 0.1836, -1.2159, -0.5191, -1.5825,  0.4003, -0.6419, -1.1341,  0.2970,\n",
        "        -1.1792,  2.1851,  2.3077,  0.3735,  1.4981,  0.6243,  1.2269],\n",
        "    [-2.7559, -0.2543,  0.6742, -0.0188, -0.3204,  0.2138,  0.2517, -2.2059,\n",
        "        -1.3797, -1.5980, -1.3527,  1.5497, -0.7449,  0.6207, -1.8088],\n",
        "    [ 0.7241,  1.2993,  0.8433,  0.1442, -1.0798,  1.7103,  0.0768, -1.0067,\n",
        "        -0.4282,  0.7578, -0.0629, -0.4202,  0.8126, -0.1174,  0.8947],\n",
        "    [ 1.7049, -0.6559,  0.4521, -0.4866,  0.2823, -0.0065, -0.6142,  0.9237,\n",
        "        -0.6907,  0.6034,  0.2700,  1.0026,  0.9323,  1.3452, -1.1236]])\n",
        "\n",
        "documents = torch.tensor(\n",
        "    [[ 0.8498,  1.4255, -1.3913, -0.0906,  2.6704, -1.5063, -1.5604, -0.4563,\n",
        "        0.4762,  0.7897, -0.1102,  0.1176,  0.3902,  1.5095, -0.3534],\n",
        "    [-0.9154, -0.1968,  0.5091,  0.0156, -1.6841, -1.1580,  1.2767,  2.6576,\n",
        "        -0.3602,  0.4782,  0.7819,  0.7402, -0.8883, -0.1158,  1.0545],\n",
        "    [-0.8661,  0.3513, -1.8400, -3.5891, -1.3286, -0.1409, -1.3466,  1.1086,\n",
        "        0.4160,  2.5859,  0.0813, -0.5245,  0.1244,  0.3139,  1.2755],\n",
        "    [ 0.1836, -1.2159, -0.5191, -1.5825,  0.4003, -0.6419, -1.1341,  0.2970,\n",
        "        -1.1792,  2.1851,  2.3077,  0.3735,  1.4981,  0.6243,  1.2269],\n",
        "    [-1.2163,  0.2481, -1.9740,  0.2509,  1.0521,  0.5903, -0.6070, -0.6650,\n",
        "        -0.1618,  0.5526,  0.6654,  0.9530, -0.5084,  1.8372, -0.2625],\n",
        "    [ 1.4968, -0.4212, -0.3566, -0.1982,  0.3722,  0.4442,  1.0164,  0.8380,\n",
        "        -0.5248, -1.1686,  1.3973, -0.6910, -0.5832, -0.2636, -1.0497]])\n",
        "\n",
        "labels = torch.eye(queries.size(0))\n",
        "assert abs(criterion(queries, documents, labels).item() - 8.74177) < 1e-4\n",
        "\n",
        "labels = torch.tensor(\n",
        "    [[0.5000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000],\n",
        "    [0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.3333],\n",
        "    [0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
        "    [0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.3333],\n",
        "    [0.5000, 0.0000, 0.0000, 0.0000, 0.5000, 0.0000],\n",
        "    [0.0000, 0.3333, 0.0000, 0.3333, 0.0000, 0.3333]])\n",
        "assert abs(criterion(queries, documents, labels).item() - 7.48024) < 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86eb590",
      "metadata": {},
      "source": [
        "## 3.Модель - 4 баллов\n",
        "\n",
        "Реализуйте класс `Embedder`, который производит расчет эмбеддинга по выходу токенизатора. Вы вольны выбирать архитектуру, но суть работы модели должна сохраняться."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138d4ee2-7f69-4229-b2ad-66785b6ac8db",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Embedder(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "# ---- Ваш код здесь ----\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1698638",
      "metadata": {},
      "source": [
        "## 4.Тестовая метрика и инференс - 5 баллов\n",
        "\n",
        "Напишите функцию `calc_recall(index, query_embeddings, query_ids, qrels, documents, columns, config)`, которая по тестовой выборке эмбеддингов запросов `query_embeddings`, описываемые id запросов `query_ids`, извлекает наиболее релевантные документы из индекса документов `index` (стройте по `sampled_documents`) и по парам позитивов `qrels` и отображению id индекса в id документов `documents` (см. класс `Columns` и определение датасета) расчитывает средний модифицированный `Recall@K` по всем запросам. `@K` берите несколько, задайте списком через `config`.\n",
        "\n",
        "$$Recall@K=\\frac{\\#[\\text{число релевантных запросу документов в top-K}]}{\\min\\left(\\#[\\text{число всех релевантных запросу документов}],\\, \\#[\\text{документов в выдаче по запросу}]\\right)}$$\n",
        "\n",
        "Для построения индекса документов используйте `faiss`.\n",
        "\n",
        "Напишите функцию `inference(embedder, texts, is_query, config)`, которая прогоняет эмбеддер по текстам, `is_query` -- флаг того, являются ли тексты запросами или нет (для задания `max_length` в токенизации).\n",
        "\n",
        "Напишите функцию `test_retriever(embedder, test_queries, test_qrels, documents, columns, config)`, которая считает тестовую метрику (запускает `calc_recall`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772fc844-c050-4e21-bbbd-3555addbada2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Считаем тестовую метрику\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00380d5c-f8d9-4618-8c8a-2bed2ffc89fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Инференсим, тестируем\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3d32d54",
      "metadata": {},
      "source": [
        "## 5.Функция обучения - 10 баллов\n",
        "\n",
        "Напишите функцию `train_retriever(embedder, train_queries, train_documents, train_qrels, test_queries, test_qrels, documents, columns, dataset_config, train_test_config, loss_config)`, которая готовит все loader'ы, обучает модель в контрастивном режиме и считает раз в эпоху тестовую метрику.\n",
        "\n",
        "Поэкспериментируйте с функцией ошибки, сделайте линейную комбинацию из `loss(q, d)` и `loss(d, q)` для обучения. Посмотрите на влияние такой смены ролей запроса и документа на итоговые метрики.\n",
        "\n",
        "Стоит использовать `gradient accumulation`, который несложно пишется руками."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0155b5e9-8b03-44a2-87f5-fcb07edf5156",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Пишем обучение\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977b80c5",
      "metadata": {},
      "source": [
        "## 6.Сборка - 3 баллов\n",
        "\n",
        "Соберите все вместе, обучите эмбеддер, посмотрите на метрики теста до обучения и после. Сделайте выводы.\n",
        "\n",
        "Подсказка: да, может случиться так, что метрики не вырастут. Правильные выводы, почему так происходит, уберегут вас от потери баллов за этот пункт (в случае если не будет ошибок в реализации в предыдущих пунктах)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47853dd2-bc0c-411c-8bbb-05024920cebd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Определяем модель\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad42d92-74ab-4a99-a731-0d0f940f4acb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Тестируем модель до обучения\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7347df7f-67c7-4621-9680-bfeb914cfa87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Запускаем обучение\")\n",
        "# ---- Конец кода ----\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baaf3a1c-d7ad-4e88-864a-9dc1a0e564a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"Тестируем после\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07a7d9a7",
      "metadata": {},
      "source": [
        "Ваши выводы туть: **Бомбордиро Крокодило**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2610d79",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
