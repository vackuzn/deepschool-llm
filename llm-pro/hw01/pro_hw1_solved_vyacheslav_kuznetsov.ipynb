{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc5o7359HRy1"
      },
      "source": [
        "# Домашнее задание: архитектура систем текстовой классификации\n",
        "\n",
        "Добро пожаловать на бизнес-кейс по текстовой классификации!\n",
        "\n",
        "В рамках данного домашнего задания вам предстоит пройти по всем этапам решения кейса, которые обычно затрагиваются при решении реальных продуктовых задач, а также кейсов на секциях по ML System Design.\n",
        "\n",
        "Часть заданий требует текстового ответа в свободной форме, часть заданий - написания кода, обучения и инференса моделей и тп. В большинстве разделов нет сугубо правильных ответов или единственно верной реализации, однако есть хорошие практики и возможность выбрать из нескольких вариантов оптимальный. Поэтому в рамках задания местами надо будет делать выбор, от которого будет зависеть качество вашего потенциального продакшн-решения, возможности его поддержки и масштабирования.\n",
        "\n",
        "Детали реализации вы можете выбирать любые, которые вам больше нравятся или кажется более удобными, в том числе по принципу \"работает быстрее аналогов без существенной потери в качестве\". Однако важное требование - **соблюдать структуру разделов в данном ноутбуке** -- это поможет решить задачу правильно, а также упростить проверку и написание фидбека по решению.\n",
        "\n",
        "Представьте, что к вам пришел бизнес и попросил сделать супер-крутую систему по категоризации новостей. Как обычно бывает, единственное, что у вас есть - это формулировка задачи от продакт-менеджера; всё остальное он ожидает от вас.\n",
        "\n",
        "Приятного кодинга!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxr2ozq9JvvB"
      },
      "source": [
        "## 1. Формулировка бизнес-задачи\n",
        "\n",
        "**Контекст (от лица бизнеса):**  \n",
        "Мы хотим автоматически распределять публикации нашего новостного портала по трем главным темам — политика, экономика, культура — чтобы:\n",
        "\n",
        "- Улучшить таргетинг рекламных блоков.  \n",
        "- Персонализировать ленту для пользователей.  \n",
        "- Снизить ручные затраты редакторов.\n",
        "\n",
        "**Чёткое описание задачи:**\n",
        "> «Для каждой новости (заголовок + текст) автоматически определить, относится ли она к разделам `политика`, `экономика`, `культура`. Возможна множественная классификация (одна новость может быть сразу в нескольких разделах).»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKP4etX9Jx9f"
      },
      "source": [
        "## 2. Бизнес-метрики - 1 балл\n",
        "\n",
        "Предложите бизнес-метрики, которые может хотеть оптимизировать бизнес в соответствии с формулировкой задачи. Предложите хотя три метрики, и постарайтесь их оцифровать, чтобы результаты были измеримы (насколько процентов что-то должно увеличиться?). Воспринимайте это как \"прицелочные\" цифры, к которым можно реалистично стремиться (реальные цифры на старте часто непонятно, но измеримые цели помогают четче формировать ожидания и текущее положение относительно них; в дальнейшем эти цифры можно корректировать на реальность)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PbFzfztvA7oP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "По задачам:\n",
            "1) улучшить targetting рекламы -> улучшить CTR (процент кликов) на рекламу, базирующийся на наших предсказаниях\n",
            "2) Персонализировать ленту для пользователей. -> ожидаем что пользователи чаще выбирают статьи из рекомендуемых, а не ищут сами. Также смотреть на процент дочитываемости статей против открытия и закрытия сразу\n",
            "3) Снизить затраты времени редакторов -> сравнить маркировку редакторов с предсказаниями моделью. \n",
            "\n",
            "Оцифровываевым метрики\n",
            "1) CTR. Нашел статью https://cordelialabs.com/blog/uncovering-the-truth-behind-ctr/ при холодном показе рекламы CTR может состовлять доли процента: 0.5 - 0.8%, при выдаче поисковых результатов 5 - 10%. Так как мы оптимисты, целимся на 10%\n",
            "2) Трекаем поведение юзеров на сайте, для каждой открытой статьи смотрим откуда человек перешел. В идеале процент переходов с рекомендаций должно быть 0.8 - 0.9, возьмем это за цель. Процент дочитываемости статей до конца пусть стремится к 1\n",
            "3) Сделать тестовую разметку статей редакторами и прогнать модель, чем точнее предсказания тем лучше\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш ответ тут\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "По задачам:\n",
        "1) улучшить targetting рекламы -> улучшить CTR (процент кликов) на рекламу, базирующийся на наших предсказаниях\n",
        "2) Персонализировать ленту для пользователей. -> ожидаем что пользователи чаще выбирают статьи из рекомендуемых, а не ищут сами. Также смотреть на процент дочитываемости статей против открытия и закрытия сразу\n",
        "3) Снизить затраты времени редакторов -> сравнить маркировку редакторов с предсказаниями моделью. \n",
        "\n",
        "Оцифровываевым метрики\n",
        "1) CTR. Нашел статью https://cordelialabs.com/blog/uncovering-the-truth-behind-ctr/ при холодном показе рекламы CTR может состовлять доли процента: 0.5 - 0.8%, при выдаче поисковых результатов 5 - 10%. Так как мы оптимисты, целимся на 10%\n",
        "2) Трекаем поведение юзеров на сайте, для каждой открытой статьи смотрим откуда человек перешел. В идеале процент переходов с рекомендаций должно быть 0.8 - 0.9, возьмем это за цель. Процент дочитываемости статей до конца пусть стремится к 1\n",
        "3) Сделать тестовую разметку статей редакторами и прогнать модель, чем точнее предсказания тем лучше\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rddOor8KJx2N"
      },
      "source": [
        "## 3. Сведение к ML-задаче - 2 балла\n",
        "\n",
        "Сведите бизнес-задачу к задаче машинного обучения, опишите входные данные и метки:\n",
        "\n",
        "- **Тип задачи**:\n",
        "- **Объект**:\n",
        "- **Метки**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GZS9B2h-BkCx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- **Тип задачи**: Multilabel classification\n",
            "- **Объект**: Новостная статья (заголовок, текст, дата публикации, источник)\n",
            "- **Метки**: политика, экономика, культура\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш ответ тут\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "- **Тип задачи**: Multilabel classification\n",
        "- **Объект**: Новостная статья (заголовок, текст, дата публикации, источник)\n",
        "- **Метки**: политика, экономика, культура\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wZaoiz3GGfg"
      },
      "source": [
        "## 4. ML-метрики - 2 балла\n",
        "\n",
        "Сформулируйте какие метрики вашей модели машинного обучения вы будете отслеживать в соответствии с ML-задачей, к которой вы свели бизнес-задачу. Укажите оффлайн метрики и предложите онлайн-метрики, которые вы в теории могли бы замерять в рамках A/B и в проде."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CP0nwXPIBq1i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Оффлайн\n",
            "  - Соответствие предсказаний разметке редакторов (precision, recall, f1, subset accuracy)\n",
            "- Онлайн\n",
            "  - бизнес метрики: CTR, удержание юзера на сайте\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш ответ тут\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "- Оффлайн\n",
        "  - Соответствие предсказаний разметке редакторов (precision, recall, f1, subset accuracy)\n",
        "- Онлайн\n",
        "  - бизнес метрики: CTR, удержание юзера на сайте\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319jOlKUKEAB"
      },
      "source": [
        "## 5. Данные и разметка - 8 баллов\n",
        "\n",
        "В данном пункте нам будет необходимо сделать магию -- за 0 рублей и две чашки кофе получить неплохую разметку, на которой можно будет обучаться.\n",
        "\n",
        "Тк у вашего новостного агенства пока еще нет ни новостей, ни логов для них, ваши коллеги уже собрали по разным новостным сайтам логи с заголовком и текстом новости (а также источником и датой на всякий) в файле crawled_data.tsv. Необходимо считать и обработать данные из этого файла, в идеале с помощью pandas DataFrame.\n",
        "\n",
        "Как мы обсуждали на лекции, по-хорошему, работа с данными должна идти немного в другой последовательности, нежели будем делать мы: обычно сначала мы собираемся с бизнесом, пишем и оттачиваем инструкцию и собираем golden dataset. В рамках данной задачи будем считать, что у нас такой возможности нет, и нам будет ок получить MVP-разметку с помощью LLM -- это быстро, задача не самая сложная для LLM, плюс в целом качество такой разметки можно контролировать и улучшать при необходимости.\n",
        "\n",
        "В этом пункте необходимо выбрать какую-нибудь open-source LLM, написать к ней промпт (можно простой и небольшой) и разметить какое-то количество данных, которое вам может показаться достаточным для обучения в этой задаче. Можете начать с небольшого количества, и постепенно его увеличивать, отслеживая, как при этом меняется качество.\n",
        "\n",
        "LLM для разметки можно выбирать любую, но вам предстоит соблюсти баланс между качеством и возможостью инферить ее на GPU. В качестве неплохой модели для разметки русскоязычных текстов можете использовать https://huggingface.co/IlyaGusev/saiga_yandexgpt_8b: ее несложно проинферить кодом и она уже оптимизирована и влезает в GPU T4 на колабе. Можно выбирать и любую другую модель, но, возможно, вам придется повозиться с ее инференсом.\n",
        "\n",
        "Далее вам необходимо будет реализовать функцию для инференса этой LLM с учетом промпта и входа, и циклом получить разметку по всем трем категориям из задачи. Будьте максимально аккуратны с используемой памятью, иначе в середине цикла инференс может падать с ошибкой Cuda Out of Memory. Для избежания этого можете после каждого инференса делать следующее:\n",
        "- torch.cuda.empty_cache()\n",
        "- перетаскивать **всё** вычисленное с GPU на CPU\n",
        "- удалять все уже использованное переменные через del\n",
        "- ограничивать размер входа и выхода\n",
        "- если падают единичные примеры -- выкидывать их\n",
        "\n",
        "В конечном счете в вашем датафрейме должны оказаться следующие колонки:\n",
        "\n",
        "`['source', 'title', 'text', 'publication_date', 'politics', 'economy',\n",
        "       'culture', 'generation']`,\n",
        "где `generation` -- ответ генеративной модели в сыром виде; 'politics', 'economy', 'culture' -- наличие категории со значением 1/0, полученные из generation.\n",
        "\n",
        "Отлаживайте разметку на небольшом семпле данных. Как только разметите нужное вам количество примеров, не забудьте сохранить их в отдельный файл, чтобы не потерять разметку.\n",
        "\n",
        "Для искушенных - можно пользоваться vLLM для ускорения инференса или together https://api.together.xyz/signin?redirectUrl=%2F (они дают один доллар бесплатно)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
            "syswgetrc = c:/progra~1/wget/etc/wgetrc\n",
            "--2025-06-02 15:41:01--  https://fs16.getcourse.ru/fileservice/file/download/a/208089/sc/254/h/eb4e7e4b8fa16455e493beb38c54747a.tsv\n",
            "Resolving fs16.getcourse.ru... 5.182.6.123\n",
            "Connecting to fs16.getcourse.ru|5.182.6.123|:443... connected.\n",
            "OpenSSL: error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol version\n",
            "Unable to establish SSL connection.\n"
          ]
        }
      ],
      "source": [
        "url = \"https://fs16.getcourse.ru/fileservice/file/download/a/208089/sc/254/h/eb4e7e4b8fa16455e493beb38c54747a.tsv\"\n",
        "!wget --no-check-certificate https://fs16.getcourse.ru/fileservice/file/download/a/208089/sc/254/h/eb4e7e4b8fa16455e493beb38c54747a.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QUyv9HCGCgQl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Считываем данные\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "Считываем данные\n",
        "\"\"\")\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read a tab-separated file (e.g., .tsv)\n",
        "df = pd.read_csv('crawled_data.tsv', sep='\\t', dtype=str)  # Forces all columns to be read as strings\n",
        "\n",
        "a = 5\n",
        "\n",
        "# If you want to infer types but preserve strings correctly:\n",
        "# df = pd.read_csv('your_file.tsv', sep='\\t', dtype={'your_column_name': str})\n",
        "\n",
        "\n",
        "\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltr6qSQbCu9S"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "    Загружаем выбранную LLM\n",
        "    В некоторых случаях может понадобиться !pip install -U accelerate bitsandbytes transformers\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jqgRv9nJU_c"
      },
      "outputs": [],
      "source": [
        "# Промпт\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "prompt_template = (\n",
        "    \"Текст промпта для разметки\"\n",
        "    )\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEVyToWxDQu2"
      },
      "outputs": [],
      "source": [
        " # Функция разметки\n",
        "\n",
        "# @torch.no_grad() # можно включить декоратор\n",
        "def annotate(text: str, max_length:int=512) -> dict:\n",
        "    \"\"\"\n",
        "    Формат markup следующий\n",
        "        markup = {\n",
        "        'politics': 0/1,\n",
        "        'economy': 0/1,\n",
        "        'culture': 0/1,\n",
        "        'corrupted': 0/1, # сломалось ли что-то при получении разметки\n",
        "        'generation': llm_generation # чтобы можно было раздебажить закоррапченные разметки\n",
        "    }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # вставляем текст в шаблон, обрезаем на всякий чтоб не падало по памяти лишний раз\n",
        "        prompt_input = prompt_template.format(text=text[:1500]) # обрезаем слишком длинные новости\n",
        "\n",
        "\n",
        "        # может понадобиться, может нет -- зависит от выбранной вами модели\n",
        "        # prompt = tokenizer.apply_chat_template([{\n",
        "        #     \"role\": \"user\",\n",
        "        #     \"content\": prompt_input\n",
        "        # }], tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "        # markup = {}\n",
        "        # with torch.no_grad():\n",
        "        #     # inference tokenizer, model ...\n",
        "\n",
        "        #     del ... # удаляем ненужные переменные\n",
        "        #     torch.cuda.empty_cache()\n",
        "\n",
        "        #     return markup\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        print(\"\"\"\n",
        "            непосредственно разметка одного текста text с помощью выбранной LLM\n",
        "        \"\"\")\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "        return markup\n",
        "\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"CUDA OOM. Освобождаем память...\")\n",
        "        torch.cuda.empty_cache()\n",
        "        return {\n",
        "            'politics': 0, 'economy': 0, 'culture': 0,\n",
        "            'corrupted': 1,\n",
        "            'generation': 'OOM_ERROR'\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4CLVAV4Entj"
      },
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "    прокачиваем в цикле выбранную LLM для разметки данных через функцию annotate, добавляем разметку в исходный датасет и сохраняем в файл\n",
        "\"\"\")\n",
        "# ---- Конец кода ----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY7-deNWA8Ui"
      },
      "source": [
        "### Разделение данных на трейн и тест - 2 балла\n",
        "\n",
        "Проведите минимальный EDA и реализуйте разделение на трейн и тест в соответствии с природой данных и постановкой задачи. В результате получите два датафрема: train_df и test_df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk6n_26tFZjn"
      },
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"EDA и разделение на трейн-тест\")\n",
        "# ---- Конец кода ----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4od8fsCo9Iy7"
      },
      "source": [
        "## 6. Архитектура и пайплайн - 5 баллов\n",
        "\n",
        "Самое существенное в данном задании - правильно выбрать ML-архитектуру решения. Подумайте, с учетом постановки задачи и целей бизнеса, как стоит построить обучение и инференс вашей модели.\n",
        "\n",
        "В любом случае вам понадобится какая-то предобученная модель. В случае, если вы остановитесь на BERT-подобной, можно выбрать любую подходящую под задачу отсюда: https://huggingface.co/models?pipeline_tag=feature-extraction&sort=trending. Вспомните, на что стоит ориентироваться при выборе эмбеддера.\n",
        "\n",
        "Если хочется выбрать BERT полегче, можете посмотреть в сторону такой модели: https://huggingface.co/cointegrated/rubert-tiny2\n",
        "\n",
        "В качестве ответа:\n",
        "- опишите, как будет выглядеть пайплайн подготовки данных, обучения и инференса вашей классификации для всех категорий.\n",
        "- опишите, почему вы выбрали именно такую архитектуру, какие у нее преимущества и какие недостатки.\n",
        "- если используете предобученную модель, то напишите какую и как ее найти, а также почему вы выбрали именно ее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7yd0hm9FyyS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Вот так будет выглядеть пайплайн: такая архитектура, такое на вход, так обрабатывается, вот такое на выход. Вот поэтому я считаю, что это самая подходящая под задачу архитектура\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xExI_ucZ8xML"
      },
      "source": [
        "## 7. Обучение модели - 10 баллов\n",
        "\n",
        "Реализуйте архитектуру и пайплайн, описанный в предыдущем пункте. Реализуйте все классы и методы, необходимые для обработки данных, обучения и инференса.\n",
        "\n",
        "Обучите модель предсказывать все указанные категории на полученных вами данных. Не забывайте считать train и val лоссы в процессе обучения. В выводе ячеек крайне желательно отобразить процесс обучения (tqdm или принты с лоссами каждую эпоху)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4wWKxZ0-41E"
      },
      "source": [
        "### Классы для обучения и подготовки данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpv-QKar-1af"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Пишем классы, обучаем\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1DBsZbuLELS"
      },
      "source": [
        "## 8. Оценка и интерпретация - 5 баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-F7cWqi8kRp"
      },
      "source": [
        "Постройте и посчитайте следующие вещи на тесте для каждой категории:\n",
        "- Графики: roc-кривую, распределение вероятностей для класса 1 и 0 (на одном графике), confusion matrix\n",
        "- Метрики: precision, recall, f1 при оптимально подобранном пороге, roc auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxix5d633ekm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "\n",
        "def evaluate_heads_with_plots_and_roc(\n",
        "    # ...,\n",
        "    label_dict: dict,\n",
        "    threshold: float = 0.5,\n",
        "    verbose: bool = True,\n",
        "    save_path: str = None\n",
        "):\n",
        "    # ...\n",
        "    #     if save_path:\n",
        "    #         plt.savefig(f\"{save_path}/{category}_cm.png\", dpi=150, bbox_inches='tight')\n",
        "    #     plt.show()\n",
        "\n",
        "    #     if verbose:\n",
        "    #         print(f\"\\n===== Категория: {category} =====\")\n",
        "    #         print(classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "    #     metrics.append({\n",
        "    #         \"category\": category,\n",
        "    #         \"accuracy\": acc,\n",
        "    #         \"precision\": pr,\n",
        "    #         \"recall\": rc,\n",
        "    #         \"f1_score\": f1,\n",
        "    #         \"auc_roc\": auc\n",
        "    #     })\n",
        "\n",
        "    # return pd.DataFrame(metrics)\n",
        "\n",
        "_ = evaluate_heads_with_plots_and_roc(...)\n",
        "print(\"метрики и графики\")\n",
        "# ---- Конец кода ----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vItux2L8CbN"
      },
      "source": [
        "## 9. Деплой и мониторинг, A/B - 2 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F24inwBM68hX"
      },
      "source": [
        "Опишите, как вы будете выкатывать в модель в прод:\n",
        "- как будет выглядеть пайплайн от момента, когда вам пришел текст и заголовок новости, до передачи вердиктов по категориям новости.\n",
        "- как вы распределите железо для инференса: будет использоваться GPU или CPU (или какая-то комбинация), и как вы это обоснуете.\n",
        "- как бы вы проводили A/B тест с учетом вашего ML и бизнес-целей? Что бы замеряли? Как бы делили на группы? Как измеряли бы значимость изменений?\n",
        "- как бы вы настраивали мониторинг? Что бы отслеживали? Для чего бы вы это делали?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CTRn3JiHElL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"вот так будет выглядеть деплой, вот это на GPU или CPU, а вот это будем мониторить\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJkQ09v8LQMy"
      },
      "source": [
        "## 10. Итерации улучшения - 3 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_dkKmxi6FHk"
      },
      "source": [
        "Проанализируйте внимательно ваше решение, какие в нем есть проблемы и что можно улучшить. Придумайте (сами) максимально полный список того, что можно в модели сделать по-другому и улучшить, чтобы повысить качество модели.\n",
        "\n",
        "**При желании** (это не повлияет на оценку), выберите одно из таких улучшений, внедрите, после чего выведите в одной ячейке метрики на тесте вашего прошлого и нового решений -- удалось ли улучшить результат?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAFayoYoHKt4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Вот так будем улучшать\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdlysHIrLWpl"
      },
      "source": [
        "## 11. Расширение категорий (10 баллов)\n",
        "\n",
        "Как это часто бывает, к вам пришел бизнес и сказал: \"мы передумали\".\n",
        "\n",
        "Всё тщательно обсудив на встрече, главный продакт-менеджер заявил, что новостное агентство нуждается в другом наборе категорий, а именно: нужно выделить новые категории, \"технологии\" и \"спорт\", а три старые в целом могут оставаться на месте (правда никто не знает, надолго ли).\n",
        "\n",
        "Итого, **новый список:** `[\"политика\",\"экономика\",\"технологии\",\"спорт\",\"культура\"]`\n",
        "\n",
        "Реализуйте это изменение и выведите новые метрики по всем категориям (старым и новым), но перед этим посмотрите на архитектуру своего решения и ответьте на вопрос -- насколько легко и удобно будет а) добавлять новые категории в вашем ML б) перекатывать сервис?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ggXeQgHRbZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Масштабируем на новые классы\")\n",
        "# ---- Конец кода ----"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
