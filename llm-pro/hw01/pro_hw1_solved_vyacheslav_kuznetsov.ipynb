{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc5o7359HRy1"
      },
      "source": [
        "# Домашнее задание: архитектура систем текстовой классификации\n",
        "\n",
        "Добро пожаловать на бизнес-кейс по текстовой классификации!\n",
        "\n",
        "В рамках данного домашнего задания вам предстоит пройти по всем этапам решения кейса, которые обычно затрагиваются при решении реальных продуктовых задач, а также кейсов на секциях по ML System Design.\n",
        "\n",
        "Часть заданий требует текстового ответа в свободной форме, часть заданий - написания кода, обучения и инференса моделей и тп. В большинстве разделов нет сугубо правильных ответов или единственно верной реализации, однако есть хорошие практики и возможность выбрать из нескольких вариантов оптимальный. Поэтому в рамках задания местами надо будет делать выбор, от которого будет зависеть качество вашего потенциального продакшн-решения, возможности его поддержки и масштабирования.\n",
        "\n",
        "Детали реализации вы можете выбирать любые, которые вам больше нравятся или кажется более удобными, в том числе по принципу \"работает быстрее аналогов без существенной потери в качестве\". Однако важное требование - **соблюдать структуру разделов в данном ноутбуке** -- это поможет решить задачу правильно, а также упростить проверку и написание фидбека по решению.\n",
        "\n",
        "Представьте, что к вам пришел бизнес и попросил сделать супер-крутую систему по категоризации новостей. Как обычно бывает, единственное, что у вас есть - это формулировка задачи от продакт-менеджера; всё остальное он ожидает от вас.\n",
        "\n",
        "Приятного кодинга!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxr2ozq9JvvB"
      },
      "source": [
        "## 1. Формулировка бизнес-задачи\n",
        "\n",
        "**Контекст (от лица бизнеса):**  \n",
        "Мы хотим автоматически распределять публикации нашего новостного портала по трем главным темам — политика, экономика, культура — чтобы:\n",
        "\n",
        "- Улучшить таргетинг рекламных блоков.  \n",
        "- Персонализировать ленту для пользователей.  \n",
        "- Снизить ручные затраты редакторов.\n",
        "\n",
        "**Чёткое описание задачи:**\n",
        "> «Для каждой новости (заголовок + текст) автоматически определить, относится ли она к разделам `политика`, `экономика`, `культура`. Возможна множественная классификация (одна новость может быть сразу в нескольких разделах).»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKP4etX9Jx9f"
      },
      "source": [
        "## 2. Бизнес-метрики - 1 балл\n",
        "\n",
        "Предложите бизнес-метрики, которые может хотеть оптимизировать бизнес в соответствии с формулировкой задачи. Предложите хотя три метрики, и постарайтесь их оцифровать, чтобы результаты были измеримы (насколько процентов что-то должно увеличиться?). Воспринимайте это как \"прицелочные\" цифры, к которым можно реалистично стремиться (реальные цифры на старте часто непонятно, но измеримые цели помогают четче формировать ожидания и текущее положение относительно них; в дальнейшем эти цифры можно корректировать на реальность)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PbFzfztvA7oP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "По задачам:\n",
            "1) улучшить targetting рекламы -> улучшить CTR (процент кликов) на рекламу, базирующийся на наших предсказаниях\n",
            "2) Персонализировать ленту для пользователей. -> ожидаем что пользователи чаще выбирают статьи из рекомендуемых, а не ищут сами. Также смотреть на процент дочитываемости статей против открытия и закрытия сразу\n",
            "3) Снизить затраты времени редакторов -> сравнить маркировку редакторов с предсказаниями моделью. \n",
            "\n",
            "Оцифровываевым метрики\n",
            "1) CTR. Нашел статью https://cordelialabs.com/blog/uncovering-the-truth-behind-ctr/ при холодном показе рекламы CTR может состовлять доли процента: 0.5 - 0.8%, при выдаче поисковых результатов 5 - 10%. Так как мы оптимисты, целимся на 10%\n",
            "2) Трекаем поведение юзеров на сайте, для каждой открытой статьи смотрим откуда человек перешел. В идеале процент переходов с рекомендаций должно быть 0.8 - 0.9, возьмем это за цель. Процент дочитываемости статей до конца пусть стремится к 1\n",
            "3) Сделать тестовую разметку статей редакторами и прогнать модель, чем точнее предсказания тем лучше\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш ответ тут\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "По задачам:\n",
        "1) улучшить targetting рекламы -> улучшить CTR (процент кликов) на рекламу, базирующийся на наших предсказаниях\n",
        "2) Персонализировать ленту для пользователей. -> ожидаем что пользователи чаще выбирают статьи из рекомендуемых, а не ищут сами. Также смотреть на процент дочитываемости статей против открытия и закрытия сразу\n",
        "3) Снизить затраты времени редакторов -> сравнить маркировку редакторов с предсказаниями моделью. \n",
        "\n",
        "Оцифровываевым метрики\n",
        "1) CTR. Нашел статью https://cordelialabs.com/blog/uncovering-the-truth-behind-ctr/ при холодном показе рекламы CTR может состовлять доли процента: 0.5 - 0.8%, при выдаче поисковых результатов 5 - 10%. Так как мы оптимисты, целимся на 10%\n",
        "2) Трекаем поведение юзеров на сайте, для каждой открытой статьи смотрим откуда человек перешел. В идеале процент переходов с рекомендаций должно быть 0.8 - 0.9, возьмем это за цель. Процент дочитываемости статей до конца пусть стремится к 1\n",
        "3) Сделать тестовую разметку статей редакторами и прогнать модель, чем точнее предсказания тем лучше\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rddOor8KJx2N"
      },
      "source": [
        "## 3. Сведение к ML-задаче - 2 балла\n",
        "\n",
        "Сведите бизнес-задачу к задаче машинного обучения, опишите входные данные и метки:\n",
        "\n",
        "- **Тип задачи**:\n",
        "- **Объект**:\n",
        "- **Метки**:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GZS9B2h-BkCx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- **Тип задачи**: Multilabel classification\n",
            "- **Объект**: Новостная статья (заголовок, текст, дата публикации, источник)\n",
            "- **Метки**: политика, экономика, культура\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш ответ тут\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "- **Тип задачи**: Multilabel classification\n",
        "- **Объект**: Новостная статья (заголовок, текст, дата публикации, источник)\n",
        "- **Метки**: политика, экономика, культура\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wZaoiz3GGfg"
      },
      "source": [
        "## 4. ML-метрики - 2 балла\n",
        "\n",
        "Сформулируйте какие метрики вашей модели машинного обучения вы будете отслеживать в соответствии с ML-задачей, к которой вы свели бизнес-задачу. Укажите оффлайн метрики и предложите онлайн-метрики, которые вы в теории могли бы замерять в рамках A/B и в проде."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CP0nwXPIBq1i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "- Оффлайн\n",
            "  - Соответствие предсказаний разметке редакторов (precision, recall, f1, subset accuracy)\n",
            "- Онлайн\n",
            "  - бизнес метрики: CTR, удержание юзера на сайте\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ваш ответ тут\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "- Оффлайн\n",
        "  - Соответствие предсказаний разметке редакторов (precision, recall, f1, subset accuracy)\n",
        "- Онлайн\n",
        "  - бизнес метрики: CTR, удержание юзера на сайте\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319jOlKUKEAB"
      },
      "source": [
        "## 5. Данные и разметка - 8 баллов\n",
        "\n",
        "В данном пункте нам будет необходимо сделать магию -- за 0 рублей и две чашки кофе получить неплохую разметку, на которой можно будет обучаться.\n",
        "\n",
        "Тк у вашего новостного агенства пока еще нет ни новостей, ни логов для них, ваши коллеги уже собрали по разным новостным сайтам логи с заголовком и текстом новости (а также источником и датой на всякий) в файле crawled_data.tsv. Необходимо считать и обработать данные из этого файла, в идеале с помощью pandas DataFrame.\n",
        "\n",
        "Как мы обсуждали на лекции, по-хорошему, работа с данными должна идти немного в другой последовательности, нежели будем делать мы: обычно сначала мы собираемся с бизнесом, пишем и оттачиваем инструкцию и собираем golden dataset. В рамках данной задачи будем считать, что у нас такой возможности нет, и нам будет ок получить MVP-разметку с помощью LLM -- это быстро, задача не самая сложная для LLM, плюс в целом качество такой разметки можно контролировать и улучшать при необходимости.\n",
        "\n",
        "В этом пункте необходимо выбрать какую-нибудь open-source LLM, написать к ней промпт (можно простой и небольшой) и разметить какое-то количество данных, которое вам может показаться достаточным для обучения в этой задаче. Можете начать с небольшого количества, и постепенно его увеличивать, отслеживая, как при этом меняется качество.\n",
        "\n",
        "LLM для разметки можно выбирать любую, но вам предстоит соблюсти баланс между качеством и возможостью инферить ее на GPU. В качестве неплохой модели для разметки русскоязычных текстов можете использовать https://huggingface.co/IlyaGusev/saiga_yandexgpt_8b: ее несложно проинферить кодом и она уже оптимизирована и влезает в GPU T4 на колабе. Можно выбирать и любую другую модель, но, возможно, вам придется повозиться с ее инференсом.\n",
        "\n",
        "Далее вам необходимо будет реализовать функцию для инференса этой LLM с учетом промпта и входа, и циклом получить разметку по всем трем категориям из задачи. Будьте максимально аккуратны с используемой памятью, иначе в середине цикла инференс может падать с ошибкой Cuda Out of Memory. Для избежания этого можете после каждого инференса делать следующее:\n",
        "- torch.cuda.empty_cache()\n",
        "- перетаскивать **всё** вычисленное с GPU на CPU\n",
        "- удалять все уже использованное переменные через del\n",
        "- ограничивать размер входа и выхода\n",
        "- если падают единичные примеры -- выкидывать их\n",
        "\n",
        "В конечном счете в вашем датафрейме должны оказаться следующие колонки:\n",
        "\n",
        "`['source', 'title', 'text', 'publication_date', 'politics', 'economy',\n",
        "       'culture', 'generation']`,\n",
        "где `generation` -- ответ генеративной модели в сыром виде; 'politics', 'economy', 'culture' -- наличие категории со значением 1/0, полученные из generation.\n",
        "\n",
        "Отлаживайте разметку на небольшом семпле данных. Как только разметите нужное вам количество примеров, не забудьте сохранить их в отдельный файл, чтобы не потерять разметку.\n",
        "\n",
        "Для искушенных - можно пользоваться vLLM для ускорения инференса или together https://api.together.xyz/signin?redirectUrl=%2F (они дают один доллар бесплатно)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#url = \"https://fs16.getcourse.ru/fileservice/file/download/a/208089/sc/254/h/eb4e7e4b8fa16455e493beb38c54747a.tsv\"\n",
        "#!wget -O news.tsv --no-check-certificate https://fs16.getcourse.ru/fileservice/file/download/a/208089/sc/254/h/eb4e7e4b8fa16455e493beb38c54747a.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install -U accelerate bitsandbytes transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data preprocessing\n",
        "\n",
        "\n",
        "import re\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "\n",
        "\n",
        "RU_MONTHS = {\n",
        "    'января': '01', 'февраля': '02', 'марта': '03',\n",
        "    'апреля': '04', 'мая': '05', 'июня': '06',\n",
        "    'июля': '07', 'августа': '08', 'сентября': '09',\n",
        "    'октября': '10', 'ноября': '11', 'декабря': '12',\n",
        "}\n",
        "\n",
        "\n",
        "def parse_timestamp(ts: str) -> datetime:\n",
        "    ts = ts.strip()\n",
        "\n",
        "    # Case 1: Unix timestamp\n",
        "    if ts.isdigit():\n",
        "        return datetime.fromtimestamp(int(ts))\n",
        "\n",
        "    # Case 2: Strip updated parts like \"(обновлено: 21:13 31.08.2020)\"\n",
        "    ts = re.sub(r\"\\(обновлено:.*?\\)\", \"\", ts).strip()\n",
        "\n",
        "    # Case 3: Russian date with month name (with or without comma)\n",
        "    if any(month in ts for month in RU_MONTHS):\n",
        "        parts = ts.replace(\",\", \"\").split()\n",
        "        if len(parts) >= 4:\n",
        "            time_part = parts[0]\n",
        "            day, month_ru, year = parts[1:4]\n",
        "            month = RU_MONTHS.get(month_ru)\n",
        "            if not month:\n",
        "                raise ValueError(f\"Unrecognized Russian month: '{month_ru}'\")\n",
        "            return datetime.strptime(f\"{year}-{month}-{day} {time_part}\", \"%Y-%m-%d %H:%M\")\n",
        "\n",
        "    # Case 4: DD.MM.YYYY format\n",
        "    match = re.search(r\"(\\d{1,2}:\\d{2})\\s+(\\d{1,2})\\.(\\d{1,2})\\.(\\d{4})\", ts)\n",
        "    if match:\n",
        "        time_str, day, month, year = match.groups()\n",
        "        return datetime.strptime(f\"{year}-{month}-{day} {time_str}\", \"%Y-%m-%d %H:%M\")\n",
        "\n",
        "    # Case 5: ISO or fallback\n",
        "    try:\n",
        "        return parser.parse(ts)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Unrecognized timestamp format: {ts}\") from e\n",
        "    \n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    # Replace non-breaking space and other similar characters\n",
        "    text = text.replace('\\xa0', ' ')\n",
        "    \n",
        "    # Remove leading/trailing whitespace including newlines\n",
        "    text = text.strip()\n",
        "\n",
        "    # Collapse multiple whitespace and newlines into a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QUyv9HCGCgQl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Считываем данные\n",
            "\n",
            "source       string[python]\n",
            "title        string[python]\n",
            "content      string[python]\n",
            "posted_ts    datetime64[ns]\n",
            "dtype: object\n",
            "     source                                           title  \\\n",
            "0  lenta.ru                                  Синий богатырь   \n",
            "1  lenta.ru  Загитова согласилась вести «Ледниковый период»   \n",
            "2  lenta.ru       Объяснена опасность однообразного питания   \n",
            "3  lenta.ru                      «Предохраняться? А зачем?»   \n",
            "4  lenta.ru     Ефремов систематически употреблял наркотики   \n",
            "\n",
            "                                             content           posted_ts  \n",
            "0  В 1930-е годы Советский Союз охватила лихорадк... 2020-08-30 00:01:00  \n",
            "1  Олимпийская чемпионка по фигурному катанию Али... 2020-08-31 20:04:00  \n",
            "2  Российский врач-диетолог Римма Мойсенко объясн... 2020-08-31 20:07:00  \n",
            "3  В 2019 году телеканал «Ю» запустил адаптацию з... 2020-08-30 00:04:00  \n",
            "4  Актер Михаил Ефремов систематически употреблял... 2020-08-31 18:27:00  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>posted_ts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lenta.ru</td>\n",
              "      <td>Синий богатырь</td>\n",
              "      <td>В 1930-е годы Советский Союз охватила лихорадк...</td>\n",
              "      <td>2020-08-30 00:01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lenta.ru</td>\n",
              "      <td>Загитова согласилась вести «Ледниковый период»</td>\n",
              "      <td>Олимпийская чемпионка по фигурному катанию Али...</td>\n",
              "      <td>2020-08-31 20:04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lenta.ru</td>\n",
              "      <td>Объяснена опасность однообразного питания</td>\n",
              "      <td>Российский врач-диетолог Римма Мойсенко объясн...</td>\n",
              "      <td>2020-08-31 20:07:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lenta.ru</td>\n",
              "      <td>«Предохраняться? А зачем?»</td>\n",
              "      <td>В 2019 году телеканал «Ю» запустил адаптацию з...</td>\n",
              "      <td>2020-08-30 00:04:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lenta.ru</td>\n",
              "      <td>Ефремов систематически употреблял наркотики</td>\n",
              "      <td>Актер Михаил Ефремов систематически употреблял...</td>\n",
              "      <td>2020-08-31 18:27:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21668</th>\n",
              "      <td>tjournal.ru</td>\n",
              "      <td>Россия прекратила поставки нефти на белорусски...</td>\n",
              "      <td>Россия прекратила поставки нефти на белорусски...</td>\n",
              "      <td>2020-01-03 14:04:34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21669</th>\n",
              "      <td>tjournal.ru</td>\n",
              "      <td>Во Владивостоке в новогоднюю ночь сожгли фигур...</td>\n",
              "      <td>Светодиодную конструкцию не хотели убирать из-...</td>\n",
              "      <td>2020-01-01 09:22:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21670</th>\n",
              "      <td>tjournal.ru</td>\n",
              "      <td>Дым от австралийских лесных пожаров достиг Нов...</td>\n",
              "      <td>Власти направили военные корабли и авиацию для...</td>\n",
              "      <td>2020-01-01 08:35:24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21671</th>\n",
              "      <td>tjournal.ru</td>\n",
              "      <td>Около 200 жителей закрытого Новоуральска встре...</td>\n",
              "      <td>С каждым годом количество горожан, выбирающих ...</td>\n",
              "      <td>2020-01-01 16:56:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21672</th>\n",
              "      <td>tjournal.ru</td>\n",
              "      <td>Папа римский шлёпнул по руке женщину, которая ...</td>\n",
              "      <td>Признав, что подал «плохой пример». 96 коммент...</td>\n",
              "      <td>2020-01-01 16:37:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21673 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            source                                              title  \\\n",
              "0         lenta.ru                                     Синий богатырь   \n",
              "1         lenta.ru     Загитова согласилась вести «Ледниковый период»   \n",
              "2         lenta.ru          Объяснена опасность однообразного питания   \n",
              "3         lenta.ru                         «Предохраняться? А зачем?»   \n",
              "4         lenta.ru        Ефремов систематически употреблял наркотики   \n",
              "...            ...                                                ...   \n",
              "21668  tjournal.ru  Россия прекратила поставки нефти на белорусски...   \n",
              "21669  tjournal.ru  Во Владивостоке в новогоднюю ночь сожгли фигур...   \n",
              "21670  tjournal.ru  Дым от австралийских лесных пожаров достиг Нов...   \n",
              "21671  tjournal.ru  Около 200 жителей закрытого Новоуральска встре...   \n",
              "21672  tjournal.ru  Папа римский шлёпнул по руке женщину, которая ...   \n",
              "\n",
              "                                                 content           posted_ts  \n",
              "0      В 1930-е годы Советский Союз охватила лихорадк... 2020-08-30 00:01:00  \n",
              "1      Олимпийская чемпионка по фигурному катанию Али... 2020-08-31 20:04:00  \n",
              "2      Российский врач-диетолог Римма Мойсенко объясн... 2020-08-31 20:07:00  \n",
              "3      В 2019 году телеканал «Ю» запустил адаптацию з... 2020-08-30 00:04:00  \n",
              "4      Актер Михаил Ефремов систематически употреблял... 2020-08-31 18:27:00  \n",
              "...                                                  ...                 ...  \n",
              "21668  Россия прекратила поставки нефти на белорусски... 2020-01-03 14:04:34  \n",
              "21669  Светодиодную конструкцию не хотели убирать из-... 2020-01-01 09:22:31  \n",
              "21670  Власти направили военные корабли и авиацию для... 2020-01-01 08:35:24  \n",
              "21671  С каждым годом количество горожан, выбирающих ... 2020-01-01 16:56:08  \n",
              "21672  Признав, что подал «плохой пример». 96 коммент... 2020-01-01 16:37:02  \n",
              "\n",
              "[21673 rows x 4 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "Считываем данные\n",
        "\"\"\")\n",
        "\n",
        "# Note: Will fail if input file is too large to fit into RAM, stream processing will help, but works ok this input\n",
        "# data is dirty, some article content has \\n, so it's not possible to do simple \\n split and then \\t split, pd.read_csv('file.tsv') does not work\n",
        "\n",
        "\n",
        "def load_content_from_file() -> list[dict]:\n",
        "    with open('news.tsv', 'r', encoding='utf-8') as f:\n",
        "        entries = f.read().split(\"\\t\")\n",
        "\n",
        "    parsed = []\n",
        "\n",
        "    for entry_idx in range(0, len(entries) - 1, 3):\n",
        "        if '\\n' in entries[entry_idx]:\n",
        "            src = entries[entry_idx].split(\"\\n\")[1]\n",
        "        else:\n",
        "            src = entries[entry_idx]\n",
        "\n",
        "        title = entries[entry_idx + 1]\n",
        "        content = entries[entry_idx + 2]\n",
        "        posted_ts = entries[entry_idx + 3].split(\"\\n\")[0]  \n",
        "\n",
        "        parsed.append(\n",
        "            {\n",
        "                \"source\": src,\n",
        "                \"title\": normalize_text(title),\n",
        "                \"content\": normalize_text(content),\n",
        "                \"posted_ts\": parse_timestamp(posted_ts).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        )\n",
        "    \n",
        "    return parsed\n",
        "\n",
        "\n",
        "def to_dataframe(data: list[dict]) -> pd.DataFrame:\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    # Ensure column types\n",
        "    df = df.astype({\n",
        "        \"source\": \"string\",\n",
        "        \"title\": \"string\",\n",
        "        \"content\": \"string\"\n",
        "    })\n",
        "    df[\"posted_ts\"] = pd.to_datetime(df[\"posted_ts\"], errors=\"coerce\")  # handle invalid timestamps gracefully\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "data_json = load_content_from_file()\n",
        "df = to_dataframe(data_json)\n",
        "\n",
        "print(df.dtypes)\n",
        "print(df.head())\n",
        "\n",
        "df\n",
        "\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "for i in range(0,7,3):\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Разметка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use together ai\n",
        "from dotenv import load_dotenv\n",
        "from together import Together\n",
        "\n",
        "load_dotenv()\n",
        "client = Together()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'culture'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def classify_article(title: str, content: str) -> str:\n",
        "    prompt = \"\"\"\n",
        "    Given article title and article text, determine which categories does the article fall into.\n",
        "\n",
        "    There are available categories:\n",
        "    politics, economy, culture\n",
        "\n",
        "    Each article can fall into zero or more categories.\n",
        "\n",
        "    Answer should contain only comma separated category names, nothing else\n",
        "    \"\"\".dedent().strip()\n",
        "\n",
        "    # Combine title and content for classification\n",
        "    text_for_classification = f\"Title: ```{title}```\\nContent: ```{content}```\"\n",
        "\n",
        "    # Send to LLM for classification\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": text_for_classification}\n",
        "    ]\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "        messages=messages,\n",
        "        stream=False,\n",
        "    )\n",
        "\n",
        "    response_text = chat_completion.choices[0].message.content\n",
        "\n",
        "    return response_text\n",
        "\n",
        "\n",
        "def annotate_articles(df: pd.DataFrame, limit: int | None = None) -> pd.DataFrame:\n",
        "    # Check if classification columns exist, if not add them\n",
        "    if \"politics\" not in df.columns:\n",
        "        df[\"politics\"] = 0\n",
        "    if \"economy\" not in df.columns:\n",
        "        df[\"economy\"] = 0\n",
        "    if \"culture\" not in df.columns:\n",
        "        df[\"culture\"] = 0\n",
        "    if \"generation_result\" not in df.columns:\n",
        "        df[\"generation_result\"] = \"\"\n",
        "\n",
        "    # Get count of non-empty generation results\n",
        "    non_empty_count = df[\"generation_result\"].notna().sum()\n",
        "    if limit is None:\n",
        "        limit = len(df)\n",
        "\n",
        "    \n",
        "\n",
        "    print(f\"Number of articles already classified: {non_empty_count}\")\n",
        "    \n",
        "\n",
        "\n",
        "    df[\"generation\"] = df.apply(lambda row: classify_article(row[\"title\"], row[\"content\"]), axis=1)\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltr6qSQbCu9S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    Загружаем выбранную LLM\n",
            "    В некоторых случаях может понадобиться !pip install -U accelerate bitsandbytes transformers\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "    Загружаем выбранную LLM\n",
        "    В некоторых случаях может понадобиться !pip install -U accelerate bitsandbytes transformers\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jqgRv9nJU_c"
      },
      "outputs": [],
      "source": [
        "# Промпт\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "prompt_template = (\n",
        "    \"Текст промпта для разметки\"\n",
        "    )\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEVyToWxDQu2"
      },
      "outputs": [],
      "source": [
        " # Функция разметки\n",
        "\n",
        "# @torch.no_grad() # можно включить декоратор\n",
        "def annotate(text: str, max_length:int=512) -> dict:\n",
        "    \"\"\"\n",
        "    Формат markup следующий\n",
        "        markup = {\n",
        "        'politics': 0/1,\n",
        "        'economy': 0/1,\n",
        "        'culture': 0/1,\n",
        "        'corrupted': 0/1, # сломалось ли что-то при получении разметки\n",
        "        'generation': llm_generation # чтобы можно было раздебажить закоррапченные разметки\n",
        "    }\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # вставляем текст в шаблон, обрезаем на всякий чтоб не падало по памяти лишний раз\n",
        "        prompt_input = prompt_template.format(text=text[:1500]) # обрезаем слишком длинные новости\n",
        "\n",
        "\n",
        "        # может понадобиться, может нет -- зависит от выбранной вами модели\n",
        "        # prompt = tokenizer.apply_chat_template([{\n",
        "        #     \"role\": \"user\",\n",
        "        #     \"content\": prompt_input\n",
        "        # }], tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "        # markup = {}\n",
        "        # with torch.no_grad():\n",
        "        #     # inference tokenizer, model ...\n",
        "\n",
        "        #     del ... # удаляем ненужные переменные\n",
        "        #     torch.cuda.empty_cache()\n",
        "\n",
        "        #     return markup\n",
        "\n",
        "        # ---- Ваш код здесь ----\n",
        "        print(\"\"\"\n",
        "            непосредственно разметка одного текста text с помощью выбранной LLM\n",
        "        \"\"\")\n",
        "        # ---- Конец кода ----\n",
        "\n",
        "\n",
        "        return markup\n",
        "\n",
        "    except torch.cuda.OutOfMemoryError:\n",
        "        print(\"CUDA OOM. Освобождаем память...\")\n",
        "        torch.cuda.empty_cache()\n",
        "        return {\n",
        "            'politics': 0, 'economy': 0, 'culture': 0,\n",
        "            'corrupted': 1,\n",
        "            'generation': 'OOM_ERROR'\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4CLVAV4Entj"
      },
      "outputs": [],
      "source": [
        "# ---- Ваш код здесь ----\n",
        "print(\"\"\"\n",
        "    прокачиваем в цикле выбранную LLM для разметки данных через функцию annotate, добавляем разметку в исходный датасет и сохраняем в файл\n",
        "\"\"\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data preprocessing done in a separate file, loading results\n",
        "!wget -O annotated.csv https://github.com/vackuzn/deepschool-llm/raw/refs/heads/master/llm-pro/hw01/intermediate_results.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"annotated.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY7-deNWA8Ui"
      },
      "source": [
        "### Разделение данных на трейн и тест - 2 балла\n",
        "\n",
        "Проведите минимальный EDA и реализуйте разделение на трейн и тест в соответствии с природой данных и постановкой задачи. В результате получите два датафрема: train_df и test_df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk6n_26tFZjn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"EDA и разделение на трейн-тест\")\n",
        "\n",
        "random_state = 42\n",
        "test_ratio = 0.2\n",
        "take_items = 10000\n",
        "\n",
        "# Randomly sample rows from the original DataFrame\n",
        "df_sampled = df.sample(n=take_items, random_state=random_state)\n",
        "\n",
        "# Split sampled data into train and test sets\n",
        "train_df, test_df = train_test_split(df_sampled, test_size=0.2, random_state=random_state)\n",
        "\n",
        "print(\"Train set:\")\n",
        "print(train_df)\n",
        "\n",
        "print(\"\\nTest set:\")\n",
        "print(test_df)\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4od8fsCo9Iy7"
      },
      "source": [
        "## 6. Архитектура и пайплайн - 5 баллов\n",
        "\n",
        "Самое существенное в данном задании - правильно выбрать ML-архитектуру решения. Подумайте, с учетом постановки задачи и целей бизнеса, как стоит построить обучение и инференс вашей модели.\n",
        "\n",
        "В любом случае вам понадобится какая-то предобученная модель. В случае, если вы остановитесь на BERT-подобной, можно выбрать любую подходящую под задачу отсюда: https://huggingface.co/models?pipeline_tag=feature-extraction&sort=trending. Вспомните, на что стоит ориентироваться при выборе эмбеддера.\n",
        "\n",
        "Если хочется выбрать BERT полегче, можете посмотреть в сторону такой модели: https://huggingface.co/cointegrated/rubert-tiny2\n",
        "\n",
        "В качестве ответа:\n",
        "- опишите, как будет выглядеть пайплайн подготовки данных, обучения и инференса вашей классификации для всех категорий.\n",
        "- опишите, почему вы выбрали именно такую архитектуру, какие у нее преимущества и какие недостатки.\n",
        "- если используете предобученную модель, то напишите какую и как ее найти, а также почему вы выбрали именно ее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7yd0hm9FyyS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Вот так будет выглядеть пайплайн: такая архитектура, такое на вход, так обрабатывается, вот такое на выход. Вот поэтому я считаю, что это самая подходящая под задачу архитектура\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xExI_ucZ8xML"
      },
      "source": [
        "## 7. Обучение модели - 10 баллов\n",
        "\n",
        "Реализуйте архитектуру и пайплайн, описанный в предыдущем пункте. Реализуйте все классы и методы, необходимые для обработки данных, обучения и инференса.\n",
        "\n",
        "Обучите модель предсказывать все указанные категории на полученных вами данных. Не забывайте считать train и val лоссы в процессе обучения. В выводе ячеек крайне желательно отобразить процесс обучения (tqdm или принты с лоссами каждую эпоху)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4wWKxZ0-41E"
      },
      "source": [
        "### Классы для обучения и подготовки данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wpv-QKar-1af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пишем классы, обучаем\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/3:   0%|          | 1/1000 [01:11<19:52:21, 71.61s/it, current_loss=0.577]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Пишем классы, обучаем\")\n",
        "\n",
        "# Load tokenizer and model from huggingface\n",
        "tokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-tiny2')\n",
        "encoder = AutoModel.from_pretrained('cointegrated/rubert-tiny2')\n",
        "\n",
        "# Freeze encoder weights\n",
        "for param in encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Custom dataset class\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_length=2048):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        # Combine title and content with [SEP] token\n",
        "        text = row['title'] + ' [SEP] ' + row['content']\n",
        "        label = row['politics']\n",
        "        \n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.FloatTensor([label])\n",
        "        }\n",
        "\n",
        "# Classification head model\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, encoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.classifier = nn.Linear(encoder.config.hidden_size, 1)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "        pooled_output = outputs[0][:, 0]  # Take CLS token\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return torch.sigmoid(logits)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=3, device='cuda'):\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        total_train_loss = 0\n",
        "        train_steps = 0\n",
        "        \n",
        "        train_loop = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "        for batch in train_loop:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            total_train_loss += loss.item()\n",
        "            train_steps += 1\n",
        "            current_loss = loss.item()\n",
        "            train_loop.set_postfix({\n",
        "                'training_loss': '{:.3f}'.format(total_train_loss/train_steps),\n",
        "                'current_loss': '{:.3f}'.format(current_loss)\n",
        "            })\n",
        "            \n",
        "        avg_train_loss = total_train_loss / train_steps\n",
        "        print(f'\\nAverage training loss: {avg_train_loss:.3f}')\n",
        "        \n",
        "        # Plot training loss\n",
        "        plt.figure(figsize=(10,6))\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'Training Loss - Epoch {epoch+1}')\n",
        "        plt.xlabel('Batch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_steps = 0\n",
        "        \n",
        "        for batch in tqdm(val_loader, desc='Validation'):\n",
        "            with torch.no_grad():\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                \n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                total_val_loss += loss.item()\n",
        "                val_steps += 1\n",
        "        \n",
        "        avg_val_loss = total_val_loss / val_steps\n",
        "        print(f'Average validation loss: {avg_val_loss:.3f}')\n",
        "        \n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            # Save best model\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "            \n",
        "    print(\"Training completed!\")\n",
        "    return model\n",
        "\n",
        "# Initialize model, criterion and optimizer\n",
        "model = ClassificationHead(encoder)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = NewsDataset(train_df, tokenizer)\n",
        "val_dataset = NewsDataset(test_df, tokenizer)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "# Train model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = train_model(model, train_loader, val_loader, criterion, optimizer, device=device)\n",
        "\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1DBsZbuLELS"
      },
      "source": [
        "## 8. Оценка и интерпретация - 5 баллов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-F7cWqi8kRp"
      },
      "source": [
        "Постройте и посчитайте следующие вещи на тесте для каждой категории:\n",
        "- Графики: roc-кривую, распределение вероятностей для класса 1 и 0 (на одном графике), confusion matrix\n",
        "- Метрики: precision, recall, f1 при оптимально подобранном пороге, roc auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxix5d633ekm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ---- Ваш код здесь ----\n",
        "\n",
        "def evaluate_heads_with_plots_and_roc(\n",
        "    # ...,\n",
        "    label_dict: dict,\n",
        "    threshold: float = 0.5,\n",
        "    verbose: bool = True,\n",
        "    save_path: str = None\n",
        "):\n",
        "    # ...\n",
        "    #     if save_path:\n",
        "    #         plt.savefig(f\"{save_path}/{category}_cm.png\", dpi=150, bbox_inches='tight')\n",
        "    #     plt.show()\n",
        "\n",
        "    #     if verbose:\n",
        "    #         print(f\"\\n===== Категория: {category} =====\")\n",
        "    #         print(classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "    #     metrics.append({\n",
        "    #         \"category\": category,\n",
        "    #         \"accuracy\": acc,\n",
        "    #         \"precision\": pr,\n",
        "    #         \"recall\": rc,\n",
        "    #         \"f1_score\": f1,\n",
        "    #         \"auc_roc\": auc\n",
        "    #     })\n",
        "\n",
        "    # return pd.DataFrame(metrics)\n",
        "\n",
        "_ = evaluate_heads_with_plots_and_roc(...)\n",
        "print(\"метрики и графики\")\n",
        "# ---- Конец кода ----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vItux2L8CbN"
      },
      "source": [
        "## 9. Деплой и мониторинг, A/B - 2 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F24inwBM68hX"
      },
      "source": [
        "Опишите, как вы будете выкатывать в модель в прод:\n",
        "- как будет выглядеть пайплайн от момента, когда вам пришел текст и заголовок новости, до передачи вердиктов по категориям новости.\n",
        "- как вы распределите железо для инференса: будет использоваться GPU или CPU (или какая-то комбинация), и как вы это обоснуете.\n",
        "- как бы вы проводили A/B тест с учетом вашего ML и бизнес-целей? Что бы замеряли? Как бы делили на группы? Как измеряли бы значимость изменений?\n",
        "- как бы вы настраивали мониторинг? Что бы отслеживали? Для чего бы вы это делали?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CTRn3JiHElL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"вот так будет выглядеть деплой, вот это на GPU или CPU, а вот это будем мониторить\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJkQ09v8LQMy"
      },
      "source": [
        "## 10. Итерации улучшения - 3 балла"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_dkKmxi6FHk"
      },
      "source": [
        "Проанализируйте внимательно ваше решение, какие в нем есть проблемы и что можно улучшить. Придумайте (сами) максимально полный список того, что можно в модели сделать по-другому и улучшить, чтобы повысить качество модели.\n",
        "\n",
        "**При желании** (это не повлияет на оценку), выберите одно из таких улучшений, внедрите, после чего выведите в одной ячейке метрики на тесте вашего прошлого и нового решений -- удалось ли улучшить результат?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAFayoYoHKt4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Вот так будем улучшать\")\n",
        "# ---- Конец кода ----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdlysHIrLWpl"
      },
      "source": [
        "## 11. Расширение категорий (10 баллов)\n",
        "\n",
        "Как это часто бывает, к вам пришел бизнес и сказал: \"мы передумали\".\n",
        "\n",
        "Всё тщательно обсудив на встрече, главный продакт-менеджер заявил, что новостное агентство нуждается в другом наборе категорий, а именно: нужно выделить новые категории, \"технологии\" и \"спорт\", а три старые в целом могут оставаться на месте (правда никто не знает, надолго ли).\n",
        "\n",
        "Итого, **новый список:** `[\"политика\",\"экономика\",\"технологии\",\"спорт\",\"культура\"]`\n",
        "\n",
        "Реализуйте это изменение и выведите новые метрики по всем категориям (старым и новым), но перед этим посмотрите на архитектуру своего решения и ответьте на вопрос -- насколько легко и удобно будет а) добавлять новые категории в вашем ML б) перекатывать сервис?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ggXeQgHRbZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---- Ваш код здесь ----\n",
        "print(\"Масштабируем на новые классы\")\n",
        "# ---- Конец кода ----"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
