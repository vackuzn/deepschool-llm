{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFd4gLTldVdQ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Скачиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_FILE_PATH = \"../data/hw04/input.txt\"\n",
    "\n",
    "if \"/\" in DATA_FILE_PATH:\n",
    "    os.makedirs(os.path.dirname(DATA_FILE_PATH), exist_ok=True)\n",
    "\n",
    "if not os.path.isfile(DATA_FILE_PATH):\n",
    "    ! wget -O $DATA_FILE_PATH https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import einops\n",
    "import torch\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Tuple, List, Optional, Dict, Callable\n",
    "from jaxtyping import Float, Int\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "\n",
    "У нас есть тексты пьесы Шекспира"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_FILE_PATH) as fin:\n",
    "    text = fin.read()\n",
    "    \n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем токенайзер, обратите внимание, что у токена there должен быть вначале спецсимвол, обозначающий, что это новое слово, а не часть предыдущего! Используем модель `openai-community/gpt2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "assert tokenizer.tokenize(\"Hello there sometrashtoken\") == ['Hello', 'Ġthere', 'Ġsomet', 'r', 'ash', 'token']\n",
    "assert tokenizer.eos_token == \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В токенайзере нет спецтокена под паддинг, поэтому выставим PAD_TOKEN = EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет - 5 баллов\n",
    "\n",
    "Нам нужен Dataset - что-то, что будет держать данные.\n",
    "Почитать подробнее можно в [документации](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) или на [примерах](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). \n",
    "\n",
    "\n",
    "Если кратко:\n",
    "* Dataset должен реализовывать 2 метода: `__getitem__` для получения сэмплов и `__len__` для получения длины датасета\n",
    "* Нужна функция collate_fn - она будет собирать несколько сэмплов из датасета в один батч\n",
    "* Нужен DataLoader - объект, который будет брать объекты из датасета и с помощью collate_fn возвращать батчи\n",
    "* Нужен Sampler - объект, который помогает DataLoader выбирать батчи. В нашем случае это будет просто рандом, но можно собирать сэмплы по одинаковой длине или упорядочить в зависимости от задачи.\n",
    "\n",
    "\n",
    "Начнем с Dataset. В нем нужно дописать 3 функции, самая важная конструктор `__init__`:\n",
    "1. Принимает текст\n",
    "2. Токенизирует его\n",
    "3. Бьет на непересекающиеся сэмплы размером 200-300 токенов (длину определяем с помощью random.randint)\n",
    "3. Кладет токены (векторизированные!) в self.texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "SAMPLE_MIN_LEN = 200\n",
    "SAMPLE_MAX_LEN = 300\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, tokenizer: AutoTokenizer, text: str):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts: List[List[int]] = []\n",
    "    \n",
    "        random.seed(1)\n",
    "    \n",
    "        token_ids = self.tokenizer(text)[\"input_ids\"]\n",
    "\n",
    "        # Guarantee that all chunks have size SAMPLE_MIN_LEN..SAMPLE_MAX_LEN:\n",
    "        while token_ids:\n",
    "            min_splits = math.ceil(len(token_ids) / SAMPLE_MAX_LEN)\n",
    "            max_splits = math.floor(len(token_ids) / SAMPLE_MIN_LEN)\n",
    "\n",
    "            # To avoid case when split is not possible, for example len(token_ids) == 301-399\n",
    "            # For simplicity take equal splits at the end\n",
    "            if max_splits - min_splits <= 1:\n",
    "                chunk_size = len(token_ids) // min_splits\n",
    "            else:\n",
    "                chunk_size = random.randint(SAMPLE_MIN_LEN, SAMPLE_MAX_LEN)\n",
    "\n",
    "            self.texts.append(token_ids[:chunk_size])\n",
    "            token_ids = token_ids[chunk_size:]\n",
    "    \n",
    "    def __getitem__(self, index) -> List[int]:\n",
    "        return self.texts[index]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "    \n",
    "\n",
    "dataset = MyDataset(tokenizer, text)\n",
    "\n",
    "sample_0 = dataset.tokenizer.decode(dataset[0])\n",
    "\n",
    "assert sample_0.startswith(text[:100])\n",
    "\n",
    "print(sample_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate FN - 5 баллов\n",
    "Функция сборки, она же collate_fn. Она принимает батч сэмплов, т.е. список объектов, которые нам возвращает датасет!\n",
    "Она должна принимать `List[List[int]]` батч объектов и возвращать 2 тензора:\n",
    "\n",
    "* input_ids - `[batch, seq_len]` - батч токенов, в котором добавлены паддинги до максимальной длины в батче.\n",
    "* mask - `[batch, seq_len]` - батч масок. На позиции `[i, j]` стоит 0, если токен является паддингом, иначе 1.\n",
    "\n",
    "В качестве значения паддинга для input_ids используйте `tokenizer.pad_token_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: List[List[int]]) -> Tuple[torch.LongTensor, torch.LongTensor]:\n",
    "    # !вопрос! нам же надо дополнить до seq_len модели, а не максимальной длины в батче?\n",
    "    max_len = max([len(s) for s in batch])\n",
    "    \n",
    "    collated = torch.tensor([s + [tokenizer.pad_token_id] * (max_len - len(s)) for s in batch], dtype=torch.int64)\n",
    "    mask = (collated != tokenizer.pad_token_id).long()\n",
    "\n",
    "    return collated, mask\n",
    "\n",
    "\n",
    "batch = [\n",
    "    [1, 2, 3, 4],\n",
    "    [1, 2],\n",
    "    [1, 2, 3, 4, 5, 6, 7],\n",
    "]\n",
    "\n",
    "# !вопрос! почему паддинги добавляем справа а не слева?\n",
    "input_ids_ref = torch.LongTensor([\n",
    "    [1, 2, 3, 4, 50256, 50256, 50256],\n",
    "    [1, 2, 50256, 50256, 50256, 50256, 50256],\n",
    "    [1, 2, 3, 4, 5, 6, 7],\n",
    "])\n",
    "\n",
    "\n",
    "mask_ref = torch.LongTensor([\n",
    "    [1, 1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "])\n",
    "\n",
    "input_ids, mask = collate_fn(batch)\n",
    "\n",
    "assert (input_ids == input_ids_ref).all()\n",
    "assert (mask == mask_ref).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберем DataLoader - 5 баллов\n",
    "\n",
    "Нужно заполнить пропущенные поля и убедиться, что в датасете есть замаскированные токены!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import RandomSampler\n",
    "\n",
    "# !вопрос! надо и в sampler и в DataLoader указать BatchSize?\n",
    "BATCH_SIZE = 16\n",
    "sampler = RandomSampler(\n",
    "    data_source=dataset,\n",
    "    num_samples=BATCH_SIZE\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    sampler=sampler,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "for input_ids, mask in train_loader:\n",
    "    break\n",
    "\n",
    "print(mask)\n",
    "\n",
    "assert (mask.sum(dim=1) < mask.size(1)).sum() < mask.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Немного модфицированный блок трансформера, который мы скопируем с предыдущего занятия!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    d_model: int = 768 # он же hidden_dim - внутрення размерность модели\n",
    "    debug: bool = True\n",
    "    layer_norm_eps: float = 1e-5 \n",
    "    d_vocab: int = 50257 # он же vocab_size, размер словаря модели\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 1024 # число позиционных эмбеддингов\n",
    "    d_head: int = 64 # размерность головы аттеншена\n",
    "    d_mlp: int = 3072 # внутренняя размерность FFN-слоя\n",
    "    n_heads: int = 12 # число голов аттеншена\n",
    "    n_layers: int = 12 # число слоев трансформера\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти модули остаются без изменений!\n",
    "Скопируйте их из предыдущего домашнего задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        return self.W_E[input_ids]\n",
    "\n",
    "\n",
    "class PosEmbed(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
    "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        # !вопрос! Тут нужно более эффективно делать? Каждый раз тензор для индексирования создавать\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        index_tensor = torch.arange(seq_len).repeat(batch_size, 1)\n",
    "\n",
    "        return self.W_pos[index_tensor]\n",
    "\n",
    "    \n",
    "class Unembed(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
    "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
    "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        result = x @ self.W_U + self.b_U\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
    "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
    "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
    "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
    "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        linear_1 = x @ self.W_in + self.b_in\n",
    "        non_linear = nn.functional.gelu(linear_1, approximate=\"tanh\")\n",
    "        linear_2 = non_linear @ self.W_out + self.b_out\n",
    "\n",
    "        return linear_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSNorm - 5 баллов\n",
    "https://arxiv.org/pdf/1910.07467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.w = nn.Parameter(t.ones(cfg.d_model)) # gamma\n",
    "\n",
    "    def forward(self, x: Float[Tensor, \"batch seq_len d_model\"]) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        d_model = x.shape[2]\n",
    "\n",
    "        rms = t.sqrt((x ** 2).sum(dim=2, keepdim=True) / d_model + self.cfg.layer_norm_eps)\n",
    "\n",
    "        return (x * self.w) / rms\n",
    "\n",
    "    \n",
    "cfg_rmsnorm = Config(d_model=5)\n",
    "x = torch.Tensor([[[0.1, 0.2, 0.3, 0.4, 0.5]]])\n",
    "layer = RMSNorm(cfg_rmsnorm)\n",
    "y = torch.Tensor([[[0.3015, 0.6030, 0.9045, 1.2060, 1.5076]]])\n",
    "assert torch.allclose(y, layer(x), atol=1e-4, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Masking - 10 баллов\n",
    "\n",
    "Опять же копируем имлементацию из предыдущего кода.\n",
    "Но теперь нужно учесть и маски с паддингами.\n",
    "Для этого в `apply_causal_mask` подана mask.\n",
    "\n",
    "В оригинальном задании 3 мы считали, что паддингов нет, поэтому делали маску нижней треугольной, чтобы токен i смотрел на токен j только тогда, когда `i >= j`, т.е. токен i мог смотреть все токены до него.\n",
    "\n",
    "Теперь же нужно сверх этого добавить еще и паддинг, т.е:\n",
    "\n",
    "1. Нам дается маска `[batch_size, seq_len]` из `collate_fn`. Напомню, что на позиции `[batch_idx, m]` стоит 1, если токен настоящий или 0, если это паддинг\n",
    "2. Мы должны модифицировать нашу нижнюю треугольную маску таким образом, чтобы не только не смотреть в будущее, но и не смотреть на паддинг."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    IGNORE: Float[Tensor, \"\"]\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
    "        \n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"], mask: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        \n",
    "        # Берем размерности\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        num_heads = self.cfg.n_heads\n",
    "        d_head = self.cfg.d_head\n",
    "        \n",
    "        # 1. Трансформируем матрицы проекций в формат [d_model, d_model]\n",
    "        W_Q = self.W_Q.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_K = self.W_K.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_V = self.W_V.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        \n",
    "        b_Q = self.b_Q.view(-1)\n",
    "        b_K = self.b_K.view(-1)\n",
    "        b_V = self.b_V.view(-1)\n",
    "        \n",
    "        # 1. получаем проекции  Q, K, V\n",
    "        Q = x @ W_Q + b_Q\n",
    "        K = x @ W_K + b_K\n",
    "        V = x @ W_V + b_V\n",
    "        \n",
    "        # 2. Q x K^T\n",
    "        Q_prepared = Q.view(batch_size, seq_len, num_heads, d_head).transpose(1, 2)     # batch num_heads seq_len d_head\n",
    "        K_prepared = K.view(batch_size, seq_len, num_heads, d_head).permute(0, 2, 3, 1) # batch num_heads d_head seq_len\n",
    "\n",
    "        attn_scores = Q_prepared @ K_prepared # batch num_heads seq_len seq_len\n",
    "        \n",
    "        # 3. Нормализация\n",
    "        attn_scores /= d_head ** 0.5\n",
    "        \n",
    "        # 4. Маскирование\n",
    "        attn_scores_masked = self.apply_causal_mask(attn_scores, mask) # batch num_heads seq_len seq_len\n",
    "\n",
    "        # 5. Softmax\n",
    "        attn_scores_normalized = nn.functional.softmax(attn_scores_masked, dim=3) # batch num_heads seq_len seq_len\n",
    "\n",
    "        # 6. Финальная проекция\n",
    "        V_prepared = V.view(batch_size, seq_len, num_heads, d_head).permute(0, 2, 1, 3) # batch num_heads seq_len d_head\n",
    "        attn_scores_mult_by_V = attn_scores_normalized @ V_prepared # batch num_heads seq_len d_head\n",
    "        \n",
    "        linear_prepared = attn_scores_mult_by_V.permute(0, 2, 1, 3).reshape(batch_size, seq_len, d_model) # [batch, num_heads, seq_len, d_head] -> [batch_size, seq_len, num_heads * d_head] = [batch_size, seq_len, d_model]\n",
    "        result = linear_prepared @ self.W_O.view(d_model, d_model) + self.b_O\n",
    "\n",
    "        return result\n",
    "\n",
    "    def apply_causal_mask(\n",
    "        self, attn_scores: Float[Tensor, \"batch n_heads seq_len seq_len\"], mask: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch n_heads seq_len seq_len\"]:\n",
    "        '''\n",
    "        Applies a causal mask to attention scores, and returns masked scores.\n",
    "        Используем треугольную маску, чтобы не смотреть в будущее!\n",
    "        В качестве масикировочного значения перед софтмаксом можно использовать self.IGNORE (-inf)\n",
    "        '''\n",
    "        _, n_heads, seq_len, _ = attn_scores.shape\n",
    "\n",
    "        mask_future_tokens = t.tril(t.ones((seq_len, seq_len), dtype=t.int64))\n",
    "        mask_paddings = mask[:, None, None, :].repeat(1, n_heads, seq_len, 1)\n",
    "\n",
    "        mask_merged = mask_future_tokens * mask_paddings\n",
    "\n",
    "        masked_attn_scored = torch.masked_fill(attn_scores, mask_merged == 0, value=self.IGNORE)\n",
    "\n",
    "        return masked_attn_scored\n",
    "\n",
    "\n",
    "mask_padding = torch.LongTensor([\n",
    "    [1, 1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "])\n",
    "\n",
    "lengths = mask_padding.sum(dim=1).tolist()\n",
    "\n",
    "\n",
    "batch_size = 3\n",
    "seq_len = 7\n",
    "d_head = 8\n",
    "n_heads = 4\n",
    "\n",
    "x = torch.rand(batch_size, n_heads, seq_len, seq_len)\n",
    "\n",
    "attn = Attention(cfg)\n",
    "softmax_res = torch.softmax(attn.apply_causal_mask(x, mask_padding), dim=-1)\n",
    "\n",
    "for batch_idx in range(batch_size):\n",
    "    for head_idx in range(n_heads):\n",
    "        sm = softmax_res[batch_idx, head_idx]\n",
    "        l = lengths[batch_idx]\n",
    "        for i in range(seq_len):\n",
    "            for j in range(seq_len):\n",
    "                # i < j - Causal mask, проверяем, что не смотрим в будущее!\n",
    "                # j >= l - проверяем, что не смотрим на паддинги!\n",
    "                if i < j or j >= l:\n",
    "                    assert sm[i, j] == 0, (batch_idx, head_idx, i, j, sm[i, j])\n",
    "                \n",
    "_ = attn(torch.rand(batch_size, seq_len, 768), mask_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotary Embeddings - 5 баллов\n",
    "\n",
    "Нужно написать роторные эмбеддинги из [статьи](https://arxiv.org/pdf/2104.09864). В качестве формулы нужно взять пункт 3.4.2!\n",
    "\n",
    "Их можно использовать в attention, но это не обязательно, здесь баллы даются только за имплементацию самих роторных эмбеддингов.\n",
    "\n",
    "\n",
    "Что нужно сделать в `__init__` (все нужно делать опираясь на формулу 34 из статьи):\n",
    "1. Сделать 2 матрицы $cos(m\\theta_i)$, $sin(m\\theta_i$). Это будут матрицы размера `[max_seq_len, d_head]`\n",
    "2. Берем от матрицы синусы, косинусы.\n",
    "3. Дальше мы их добавляем в модель через register_buffer. Для удобства сразу делаем фиктивные доп размерности для batch_size, num_heads.\n",
    "\n",
    "\n",
    "Что нужно сделать в `rotate_neg_vector`:\n",
    "\n",
    "1. По формуле 34 вернуть по вектору `[x1, x2, x3, x4, ... x_{n-1}, x_n]` новый вектор `[-x2, x1, -x4, x3, ..., -x_n, x_{n-1}]`\n",
    "\n",
    "\n",
    "Что нужно сделать в `forward`:\n",
    "1. Получить вектор x' `[-x2, x1, -x4, x3, ..., -x_n, x_{n-1}]`\n",
    "2. Применить для x и x' формулу 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тесты прошли успешно!\n"
     ]
    }
   ],
   "source": [
    "class RotaryPositionalEmbeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg: Config, theta: int = 10_000):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.max_seq_len = cfg.n_ctx\n",
    "        self.theta = theta\n",
    "        self.d = cfg.d_head\n",
    "        \n",
    "\n",
    "        # Углы theta_i. Смотрите секцию 2.2 статьи для формулы!\n",
    "        # θi = 10000^(−2(i−1)/d), i ∈ [1, 2, ..., d/2]\n",
    "        freqs = torch.tensor([self.theta ** (-2 * i / self.d) for i in range(self.d // 2)]) # self.d / 2 = 8\n",
    "\n",
    "        position_id = torch.arange(0, self.max_seq_len).float()\n",
    "        \n",
    "        # нужно получить матрицу m theta_i размера [max_seq_len, self.d] вида m theta_i\n",
    "        # где m берется из position_id, а theta из freqs\n",
    "        idx_theta = position_id.unsqueeze(0).T @ freqs.unsqueeze(0) # max_seq_len x self.d / 2\n",
    "        \n",
    "        # max_seq_len, d_head\n",
    "        cos = idx_theta.cos()\n",
    "        sin = idx_theta.sin()\n",
    "        \n",
    "        # нужно продублировать размерности для формулы 34. theta_i встерчается два раза подряд в синусах и косинуса\n",
    "        # тут нам поможет torch.repeat_interleave\n",
    "        cos = cos.repeat_interleave(2, dim=1)\n",
    "        sin = sin.repeat_interleave(2, dim=1)\n",
    "        \n",
    "        # 1, max_seq_len, 1, d_head\n",
    "        self.register_buffer(\"sin\", sin.view(1, self.max_seq_len, 1, self.d))\n",
    "        self.register_buffer(\"cos\", cos.view(1, self.max_seq_len, 1, self.d))\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotate_neg_vector(x: Float[torch.Tensor, \"batch seq_len num_heads d_head\"]):\n",
    "        # На входе x = [x1, x2, x3, x4, ... x_{n-1}, x_n]\n",
    "        # На выходе x' = [-x2, x1, -x4, x3, ..., -x_n, x_{n-1}]\n",
    "        x_new = t.zeros_like(x)\n",
    "        x_new[..., 0::2] = -x[..., 1::2]\n",
    "        x_new[..., 1::2] =  x[..., 0::2]\n",
    "\n",
    "        return x_new\n",
    "    \n",
    "    def forward(self, x: Float[torch.Tensor, \"batch seq_len num_heads d_head\"]):\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        x_rotated = RotaryPositionalEmbeddings.rotate_neg_vector(x)\n",
    "        result = x * self.cos[:, :seq_len, :, :] + x_rotated * self.sin[:, :seq_len, :, :]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "num_heads = 2\n",
    "d_head = 16\n",
    "\n",
    "torch.manual_seed(1)\n",
    "x = torch.rand(batch_size, seq_len, num_heads, d_head)\n",
    "\n",
    "rope_config = Config(\n",
    "    n_heads=2,\n",
    "    d_head=16,\n",
    ")\n",
    "\n",
    "rope_layer = RotaryPositionalEmbeddings(rope_config)\n",
    "y = rope_layer(x)\n",
    "\n",
    "\n",
    "from math import sin, cos\n",
    "\n",
    "\n",
    "thetas = [10_000 ** (-2 * (i - 1) / rope_config.d_head) for i in range(1, rope_config.d_head // 2 + 1)]\n",
    "all_good = True\n",
    "for batch_idx in range(batch_size):\n",
    "    for m in range(seq_len):\n",
    "        if not all_good:\n",
    "            break\n",
    "        for head_idx in range(num_heads):\n",
    "            if not all_good:\n",
    "                break\n",
    "            for d_idx in range(d_head):\n",
    "                # 0, 2, 4\n",
    "                if d_idx % 2 == 0:\n",
    "                    val = x[batch_idx, m, head_idx, d_idx] * cos(m * thetas[d_idx // 2]) - x[batch_idx, m, head_idx, d_idx + 1] * sin(m * thetas[d_idx // 2])\n",
    "                else:\n",
    "                    val = x[batch_idx, m, head_idx, d_idx] * cos(m * thetas[d_idx // 2]) + x[batch_idx, m, head_idx, d_idx - 1] * sin(m * thetas[d_idx // 2])\n",
    "                if abs(y[batch_idx, m, head_idx, d_idx] - val) > 1e-3:\n",
    "                    print(f\"Ошибка на позиции {m} и размерности {d_idx} в голове {head_idx}\")\n",
    "                    print(f\"Полученное значение {y[batch_idx, m, head_idx, d_idx]}, референс {val}\")\n",
    "                    all_good = False\n",
    "                    break\n",
    "\n",
    "\n",
    "if all_good:\n",
    "    print(\"Тесты прошли успешно!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rope X Attention\n",
    "\n",
    "Если хотите обучаться с RoPE вместо позиционных эмбеддингов, то ниже можете написать новый класс Attention, где будете \"вращать\" Q, K. Не забудьте только дальше в DemoTransformer убрать позиционные эмбеддинги\n",
    "\n",
    "**В независимости от вашего решения напишите ответ на вопрос.**\n",
    "\n",
    "В модели есть RoPE-слой. theta = 10.000, максимальное число позиций 1024. Размерность головы (размерность RoPE для простоты 16). Какое число обучаемых параметров в RoPE-слое?\n",
    "\n",
    "Ваш ответ: вроде там нет обучамых параметров. Углы считаются по предзаданной формуле, позиции m тоже фиксированы, Q и K проходят через эту трансформацию и учатся, а в самом RoPE вроде ничего больше нет\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОПЦИОНАЛЬНО\n",
    "# class AttentionWithRope():\n",
    "#     ...\n",
    "\n",
    "\n",
    "class AttentionWithRope(nn.Module):\n",
    "    IGNORE: Float[Tensor, \"\"]\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
    "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
    "        \n",
    "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
    "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
    "\n",
    "        self.RoPE = RotaryPositionalEmbeddings(cfg)\n",
    "        \n",
    "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
    "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
    "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"], mask: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        \n",
    "        # Берем размерности\n",
    "        batch_size, seq_len, d_model = x.shape\n",
    "        num_heads = self.cfg.n_heads\n",
    "        d_head = self.cfg.d_head\n",
    "        \n",
    "        # 1. Трансформируем матрицы проекций в формат [d_model, d_model]\n",
    "        W_Q = self.W_Q.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_K = self.W_K.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        W_V = self.W_V.permute(1, 0, 2).reshape(self.cfg.d_model, self.cfg.d_model)\n",
    "        \n",
    "        b_Q = self.b_Q.view(-1)\n",
    "        b_K = self.b_K.view(-1)\n",
    "        b_V = self.b_V.view(-1)\n",
    "        \n",
    "        # 1. получаем проекции  Q, K, V\n",
    "        Q = x @ W_Q + b_Q\n",
    "        K = x @ W_K + b_K\n",
    "        V = x @ W_V + b_V\n",
    "\n",
    "        # 1.1. Apply RoPE\n",
    "        Q_rope = self.RoPE.forward(Q.view(batch_size, seq_len, num_heads, d_head)) # batch seq_len num_heads d_head\n",
    "        K_rope = self.RoPE.forward(K.view(batch_size, seq_len, num_heads, d_head)) # batch seq_len num_heads d_head\n",
    "        \n",
    "        # 2. Q x K^T\n",
    "        Q_prepared = Q_rope.transpose(1, 2)     # batch num_heads seq_len d_head\n",
    "        K_prepared = K_rope.permute(0, 2, 3, 1) # batch num_heads d_head seq_len\n",
    "\n",
    "        attn_scores = Q_prepared @ K_prepared # batch num_heads seq_len seq_len\n",
    "        \n",
    "        # 3. Нормализация\n",
    "        attn_scores /= d_head ** 0.5\n",
    "        \n",
    "        # 4. Маскирование\n",
    "        attn_scores_masked = self.apply_causal_mask(attn_scores, mask) # batch num_heads seq_len seq_len\n",
    "\n",
    "        # 5. Softmax\n",
    "        attn_scores_normalized = nn.functional.softmax(attn_scores_masked, dim=3) # batch num_heads seq_len seq_len\n",
    "\n",
    "        # 6. Финальная проекция\n",
    "        V_prepared = V.view(batch_size, seq_len, num_heads, d_head).permute(0, 2, 1, 3) # batch num_heads seq_len d_head\n",
    "        attn_scores_mult_by_V = attn_scores_normalized @ V_prepared # batch num_heads seq_len d_head\n",
    "        \n",
    "        linear_prepared = attn_scores_mult_by_V.permute(0, 2, 1, 3).reshape(batch_size, seq_len, d_model) # [batch, num_heads, seq_len, d_head] -> [batch_size, seq_len, num_heads * d_head] = [batch_size, seq_len, d_model]\n",
    "        result = linear_prepared @ self.W_O.view(d_model, d_model) + self.b_O\n",
    "\n",
    "        return result\n",
    "\n",
    "    def apply_causal_mask(\n",
    "        self, attn_scores: Float[Tensor, \"batch n_heads seq_len seq_len\"], mask: Int[Tensor, \"batch seq_len\"]\n",
    "    ) -> Float[Tensor, \"batch n_heads seq_len seq_len\"]:\n",
    "        '''\n",
    "        Applies a causal mask to attention scores, and returns masked scores.\n",
    "        Используем треугольную маску, чтобы не смотреть в будущее!\n",
    "        В качестве масикировочного значения перед софтмаксом можно использовать self.IGNORE (-inf)\n",
    "        '''\n",
    "        _, n_heads, seq_len, _ = attn_scores.shape\n",
    "\n",
    "        mask_future_tokens = t.tril(t.ones((seq_len, seq_len), dtype=t.int64))\n",
    "        mask_paddings = mask[:, None, None, :].repeat(1, n_heads, seq_len, 1)\n",
    "\n",
    "        mask_merged = mask_future_tokens * mask_paddings\n",
    "\n",
    "        masked_attn_scored = torch.masked_fill(attn_scores, mask_merged == 0, value=self.IGNORE)\n",
    "\n",
    "        return masked_attn_scored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем Transformer - 5 баллов\n",
    "\n",
    "1. В TransformerBlock и DemoTransformer немного модифицируем код из предыдущего задания, чтобы передавать mask в слои аттеншена.\n",
    "2. В зависимости от того, хотим ли мы использовать RoPE или не хотим меняется также то, используем ли мы Positional Embeddings или нет!\n",
    "\n",
    "В задании не будут сниматься баллы, если используются абсолютные позиционные эмбеддинги.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.ln1 = RMSNorm(cfg)\n",
    "        self.attn = Attention(cfg)\n",
    "        self.ln2 = RMSNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"], mask: Float[Tensor, \"batch seq_len\"] \n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        #attn = self.attn(self.ln1(x), mask)\n",
    "\n",
    "        x_ln1 = self.ln1.forward(x)\n",
    "        x_attn = self.attn.forward(x_ln1, mask)\n",
    "\n",
    "        x_with_attn = x + x_attn\n",
    "\n",
    "        x_ln2 = self.ln2.forward(x_with_attn)\n",
    "        x_ffn = self.mlp.forward(x_ln2)\n",
    "\n",
    "        x_res = x_with_attn + x_ffn\n",
    "        return x_res\n",
    "\n",
    "\n",
    "class DemoTransformer(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.pos_embed = PosEmbed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = RMSNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"], mask: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        token_emb = self.embed.forward(input_ids)\n",
    "        pos_emb = self.pos_embed.forward(input_ids)\n",
    "        emb = token_emb + pos_emb\n",
    "\n",
    "        x = emb\n",
    "        for transformer_block in self.blocks:\n",
    "            x = transformer_block.forward(x, mask)\n",
    "\n",
    "        x_ln = self.ln_final.forward(x)\n",
    "        out_ids = self.unembed(x_ln)\n",
    "\n",
    "        return out_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoPE version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlockWithRope(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.ln1 = RMSNorm(cfg)\n",
    "        self.attn = AttentionWithRope(cfg)\n",
    "        self.ln2 = RMSNorm(cfg)\n",
    "        self.mlp = MLP(cfg)\n",
    "\n",
    "    def forward(\n",
    "        self, x: Float[Tensor, \"batch seq_len d_model\"], mask: Float[Tensor, \"batch seq_len\"] \n",
    "    ) -> Float[Tensor, \"batch seq_len d_model\"]:\n",
    "        x_ln1 = self.ln1.forward(x)\n",
    "        x_attn = self.attn.forward(x_ln1, mask)\n",
    "\n",
    "        x_with_attn = x + x_attn\n",
    "\n",
    "        x_ln2 = self.ln2.forward(x_with_attn)\n",
    "        x_ffn = self.mlp.forward(x_ln2)\n",
    "\n",
    "        x_res = x_with_attn + x_ffn\n",
    "        return x_res\n",
    "\n",
    "\n",
    "class DemoTransformerWithRope(nn.Module):\n",
    "    def __init__(self, cfg: Config):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.embed = Embed(cfg)\n",
    "        self.blocks = nn.ModuleList([TransformerBlockWithRope(cfg) for _ in range(cfg.n_layers)])\n",
    "        self.ln_final = RMSNorm(cfg)\n",
    "        self.unembed = Unembed(cfg)\n",
    "\n",
    "    def forward(self, input_ids: Int[Tensor, \"batch seq_len\"], mask: Int[Tensor, \"batch seq_len\"]) -> Float[Tensor, \"batch seq_len d_vocab\"]:\n",
    "        token_emb = self.embed.forward(input_ids)\n",
    "        \n",
    "        x = token_emb\n",
    "        for transformer_block in self.blocks:\n",
    "            x = transformer_block.forward(x, mask)\n",
    "\n",
    "        x_ln = self.ln_final.forward(x)\n",
    "        out_ids = self.unembed(x_ln)\n",
    "\n",
    "        return out_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальные проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_transformer_with_rope = True\n",
    "\n",
    "train_config = Config(\n",
    "    d_model=128,\n",
    "    n_ctx=512,\n",
    "    n_heads=8,\n",
    "    d_head=16,\n",
    "    d_mlp=512,\n",
    "    n_layers=12\n",
    ")\n",
    "\n",
    "if use_transformer_with_rope:\n",
    "    model = DemoTransformerWithRope(train_config)\n",
    "else:\n",
    "    model = DemoTransformer(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_ids, mask in train_loader:\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    p = model(input_ids, mask)\n",
    "\n",
    "assert list(p.shape) == [input_ids.size(0), input_ids.size(1), train_config.d_vocab]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение - 5 баллов\n",
    "\n",
    "Здесь нужно написать обычный training loop! Но он не так уж и прост. Давайте по шагам разберемся, как нам быть:\n",
    "1. Берем input_ids, mask, прогоняем через модель, получаем тензор logits `[batch_size, seq_len, vocab_size]`\n",
    "2. В качестве меток мы берем input_ids! Только нужно их обрезать по размерности seq_len таким образом, чтобы i-й токен предсказывал (i + 1)-й!\n",
    "\n",
    "3. В качестве предиктов берем logits! Его тоже нужно правильно обрезать, т.к. по последнему токену нам нечего предсказывать.\n",
    "\n",
    "4. Паддингам ставим метки -100, это значение ignore_loss, [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) его игнорирует при подсчете лососв!\n",
    "5. Превращаем p в тензор `[batch_size * (seq_len - 1), vocab_size]`, вектор правильных меток labels (из input_ids) превращаем в `[batch_size * (seq_len - 1)]`, считаем функцию потерь!\n",
    "6. Не забываем все стандартные вещи в training loop: обнуление градиентов, backward, шаг оптимизации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале напишем функцию потерь!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "pad_id = 50256\n",
    "\n",
    "def calculate_loss(criterion, logits, input_ids, pad_id = pad_id):\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "\n",
    "    logits_prepared = logits[:, :-1, :].reshape(batch_size * (seq_len - 1), vocab_size)\n",
    "    input_ids_prepared = input_ids[:, 1:].reshape(batch_size * (seq_len - 1))\n",
    "\n",
    "    input_ids_prepared[input_ids_prepared == pad_id] = criterion.ignore_index\n",
    "\n",
    "    loss = criterion(logits_prepared, input_ids_prepared)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 4\n",
    "num_classes = 7\n",
    "\n",
    "input_ids = torch.LongTensor(\n",
    "    [\n",
    "        [0, 1,  pad_id, pad_id],\n",
    "        [0, 1, 2, 3]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# batch_size, seq_len, num_classes\n",
    "logits = torch.Tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999, 0.3971],\n",
    "            [0.7544, 0.5695, 0.4388, 0.6387, 0.5247, 0.6826, 0.3051],\n",
    "            [0.4635, 0.4550, 0.5725, 0.4980, 0.9371, 0.6556, 0.3138],\n",
    "            [0.1980, 0.4162, 0.2843, 0.3398, 0.5239, 0.7981, 0.7718]\n",
    "        ],\n",
    "\n",
    "        [\n",
    "            [0.0112, 0.8100, 0.6397, 0.9743, 0.8300, 0.0444, 0.0246],\n",
    "            [0.2588, 0.9391, 0.4167, 0.7140, 0.2676, 0.9906, 0.2885],\n",
    "            [0.8750, 0.5059, 0.2366, 0.7570, 0.2346, 0.6471, 0.3556],\n",
    "            [0.4452, 0.0193, 0.2616, 0.7713, 0.3785, 0.9980, 0.9008]\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "loss = calculate_loss(criterion, logits, input_ids)\n",
    "\n",
    "assert abs(loss.item() - 1.9343) < 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь с помощью `calculate_loss` напишем цикл ообучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3782a8ee5445719de353f67e66570e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 2000\n",
    "\n",
    "losses = []\n",
    "model.train()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for input_ids, mask in train_loader:\n",
    "        logits = model.forward(input_ids, mask)\n",
    "        loss = calculate_loss(criterion, logits, input_ids)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # clear grads from previous batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate grads for current batch\n",
    "        loss.backward()\n",
    "\n",
    "        # update params according to current grad\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лоссы должны идти вниз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3379aca10>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация - 5 баллов\n",
    "Давайте теперь попробуем посмотреть, что у нас обучилось! Для этого проверим себя на жадной генерации. KV-cache не пишем, просто:\n",
    "1. Подаем input_ids, mask\n",
    "2. По последнему токену жадно предсказываем следующий\n",
    "3. Конактенируем этот токен к input_ids, расширяем mask\n",
    "4. Повторяем num_tokens_to_generate раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: First\n",
      "Input text + Generated First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "would prefer me they did make him full of such a\n",
      "cannot be full of rebellion; they, let's stay.\n",
      "\n",
      "First Citizen:\n",
      "You will end that before the cause to heal:\n",
      "I'll make thee half my friends.\n",
      "\n",
      "SICINIUS:\n",
      "We yet my state or no! I wouldWhy, when there was\n",
      "Have been too unpleasure'd for the world;\n",
      "You are but 'tis of a happy city, but to\n",
      "the army.\n",
      "\n",
      "First Citizen:\n",
      "So makes it as the queen by the King Richard\n",
      "action of slander.\n",
      "\n",
      "First Citizen:\n",
      "By heaven, here they are not famously, he is a\n",
      "the most trembling and so that will.\n",
      "\n",
      "First Citizen: this news, if then let it be not prevail'd by the greater private and myself for our brother He would it was for his son's no, but who, he must spoke to strike about the king and give place.\n",
      "Let's not my patricians have no more with whom many else they know, if you should call not thy countrymen have made soft, and let us both\n",
      "\n",
      "Upon his brother He that labour you, my son: for the hope it was he is his mother's wife.\n",
      "\n",
      "He made him, is then dead; for being then, I would hate, that kill this pride this eye, being the king up repose his no great comfort from this\n"
     ]
    }
   ],
   "source": [
    "input_text = text[:5]\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "mask = inputs[\"attention_mask\"]\n",
    "\n",
    "orig_size = input_ids.size(1)\n",
    "\n",
    "num_tokens_to_generate = 512\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_tokens_to_generate):\n",
    "        # Get next token\n",
    "        logits = model.forward(input_ids, mask)\n",
    "        next_token_id = t.argmax(logits[-1][-1])\n",
    "\n",
    "        # EOS token, stop generation\n",
    "        if next_token_id == tokenizer.pad_token_id:\n",
    "            break\n",
    "\n",
    "        # add token to context\n",
    "        input_ids = t.cat((input_ids, next_token_id[None, None]), dim=1)\n",
    "        mask = t.tensor([[1]]).repeat(1, input_ids.shape[-1])\n",
    "\n",
    "\n",
    "print(\"Input text:\", input_text)\n",
    "print(\"Input text + Generated\", tokenizer.decode(input_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если все прошло успешно, то мы увидим какой-то небольшой, но скорее всего повторяющийся текст.\n",
    "\n",
    "Осталось отмашстабировать модель, накинуть данных и наша LLM готова!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комментарии\n",
    "\n",
    "Отметил вопросы тегом !вопрос! в ноутбуке\n",
    "\n",
    "1. В роторных ембеддингах очень сбивает с толку в init описание\n",
    "нужно получить матрицу m theta_i размера [max_seq_len, self.d] вида m theta_i\n",
    "где m берется из position_id, а theta из freqs\n",
    "\n",
    "На шаге  \n",
    "idx_theta = ... \n",
    "получается размерность max_seq_len x self.d / 2 а не [max_seq_len, self.d] как написано\n",
    "так что путаница получается\n",
    "\n",
    "\n",
    "\n",
    "2. Typo in def calculate_loss(**criterTion**, logits, input_ids, pad_id=pad_id) которое влияет на то, что используется глобальная переменная вместо локальной, то есть функциональная проблема"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "287f177bea3a4a1ebf5d4fd0af5fc8ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "313dff4a97b64f60a4e2b4a12af40cc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3db66262f47f4e9098999b64246cd5da",
       "IPY_MODEL_545fbc08d4404b5f9e5251758ac15ee0",
       "IPY_MODEL_4bf13e51b72d4204a6e6bd723208495a"
      ],
      "layout": "IPY_MODEL_287f177bea3a4a1ebf5d4fd0af5fc8ce"
     }
    },
    "3db66262f47f4e9098999b64246cd5da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40bf9f987ee94484b44407999e1b29ac",
      "placeholder": "​",
      "style": "IPY_MODEL_fbe8106a981b4f6a847fc581a397ee79",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "40bf9f987ee94484b44407999e1b29ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bf13e51b72d4204a6e6bd723208495a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6184db87bde246fabe674a271cf5ef60",
      "placeholder": "​",
      "style": "IPY_MODEL_ca480e3ade314b44b333d83891d45bef",
      "value": " 4/4 [00:02&lt;00:00,  1.91it/s]"
     }
    },
    "545fbc08d4404b5f9e5251758ac15ee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71225365696d44afa104150576c60b9c",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eed5663c31194e72800e241234cd804c",
      "value": 4
     }
    },
    "6184db87bde246fabe674a271cf5ef60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71225365696d44afa104150576c60b9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca480e3ade314b44b333d83891d45bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eed5663c31194e72800e241234cd804c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbe8106a981b4f6a847fc581a397ee79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
